{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train YOLOv2 on LISA Dataset\n",
    "-----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.13 |Anaconda 4.4.0 (64-bit)| (default, Dec 20 2016, 23:09:15) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version) # Check Python Version\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.optimizers import Adam\n",
    "from utils.parse_input import load_data    # Data handler for LISA dataset\n",
    "from cfg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LISA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ground truth boxes: 3672 boxes\n",
      "Train: 3672 samples\n",
      "Number of classes: 31\n",
      "\n",
      "Label Sample: \n",
      "[1093.5 408.0 45.0 48.0 'doNotEnter']\n",
      "\n",
      "\n",
      "Relative Anchors using K-mean clustering [K=5]\n",
      " [[ 0.0237179   0.03571576]\n",
      " [ 0.05957714  0.08738709]\n",
      " [ 0.08816277  0.1294925 ]\n",
      " [ 0.03283318  0.04838902]\n",
      " [ 0.04450034  0.06430861]]\n"
     ]
    }
   ],
   "source": [
    "pretrained_path = \"/home/ubuntu/dataset/darknet19_544.weights\"\n",
    "\n",
    "x_train, y_train = load_data('data/training.txt')\n",
    "labels           = np.unique(y_train[:,1])\n",
    "num_classes      = len(labels)            # Count number of classes in the dataset\n",
    "print(\"Train: {} samples\\nNumber of classes: {}\".format(len(x_train),num_classes))\n",
    "print(\"\\nLabel Sample: \\n{}\".format(y_train[0]))\n",
    "\n",
    "ANCHORS       = np.array(((0.023717899133663362, 0.035715759075907606),\n",
    "(0.059577141608391594, 0.08738709207459215),\n",
    "(0.08816276658767774, 0.1294924960505529),\n",
    "(0.03283318210930825, 0.0483890193566751),\n",
    "(0.04450034340659346, 0.064308608058608)))\n",
    "print(\"\\n\\nRelative Anchors using K-mean clustering [K=5]\\n {}\".format(ANCHORS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct YOLOv2 On Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained weights have been loaded into model\n"
     ]
    }
   ],
   "source": [
    "from model.yolov2 import YOLOv2, darknet19\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session() # Avoid duplicate model\n",
    "\n",
    "darknet19 = darknet19(pretrained_path, freeze_layers=True)\n",
    "yolov2    = YOLOv2(feature_extractor=darknet19, num_anchors=len(ANCHORS), num_classes=N_CLASSES)\n",
    "model     = yolov2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# @TODO:\n",
    "#    - processed boxes are ALL relative, no sqrt w\n",
    "#    - Data gnerator label [ batch, 36]\n",
    "\n",
    "def _process_gt(y_true, output_shape):\n",
    "    \"\"\"\n",
    "    Process ground truth output\n",
    "    \"\"\"\n",
    "    OUTPUT_W = tf.cast(output_shape[0], tf.int32)\n",
    "    OUTPUT_H = tf.cast(output_shape[1], tf.int32)\n",
    "    INPUT_W  = tf.cast(32*OUTPUT_W, tf.float32)\n",
    "    INPUT_H  = tf.cast(32*OUTPUT_H, tf.float32)\n",
    "\n",
    "    y_true   = K.tile(y_true, (1, 1, 1, K.cast(OUTPUT_W*OUTPUT_H, tf.int32)*N_ANCHORS))\n",
    "    y_true   = K.reshape(y_true, [-1, OUTPUT_W, OUTPUT_H, N_ANCHORS, N_CLASSES + 5])\n",
    "    \n",
    "    #  Adjust ground truth to relative size\n",
    "    true_xy  = y_true[..., 0:2] / K.reshape([(INPUT_W), (INPUT_H)], [1, 1, 1, 1, 2])\n",
    "    true_wh  = y_true[..., 2:4] / K.reshape([(INPUT_W), (INPUT_H)], [1, 1, 1, 1, 2])\n",
    "    true_boxes = tf.concat([true_xy, true_wh], 4)\n",
    "    true_conf = y_true[...,4]\n",
    "    true_clf  = y_true[...,5:]\n",
    "    \n",
    "    return true_boxes, true_conf, true_clf\n",
    "\n",
    "\n",
    "def _process_prediction(y_pred):\n",
    "    \n",
    "    # Scaled anchors to size of feature map\n",
    "    output_shape   = K.shape(y_pred)[1:3]\n",
    "    OUTPUT_W = tf.cast(output_shape[0], tf.int32)\n",
    "    OUTPUT_H = tf.cast(output_shape[1], tf.int32)\n",
    "\n",
    "    scaled_anchors = ANCHORS*K.reshape([OUTPUT_W, OUTPUT_H], [1, 1, 1, 1, 2])\n",
    "    anchor_tensor  = K.reshape(scaled_anchors, [1, 1, 1, N_ANCHORS, 2])\n",
    "    y_pred         = K.reshape(y_pred, [-1, output_shape[0], output_shape[1], N_ANCHORS, N_CLASSES + 5])\n",
    "    \n",
    "    # Create offset map\n",
    "    cx, cy = _create_offset_map(K.shape(y_pred))\n",
    "    px     = tf.cast(anchor_tensor[...,0], dtype=tf.float32)\n",
    "    py     = tf.cast(anchor_tensor[..., 1], dtype=tf.float32)\n",
    "    \n",
    "    # Calculate Prediction in relative position (percentage)\n",
    "    OUTPUT_SIZE = tf.cast(output_shape, tf.float32)\n",
    "    bx  = (tf.sigmoid(y_pred[..., 0]) + cx) / OUTPUT_SIZE[0]\n",
    "    by  = (tf.sigmoid(y_pred[..., 1]) + cy) / OUTPUT_SIZE[1]\n",
    "    bw  = px * tf.exp(y_pred[..., 2])  / OUTPUT_SIZE[0]\n",
    "    bh  = py * tf.exp(y_pred[..., 3])  / OUTPUT_SIZE[1]\n",
    "    \n",
    "    pred_boxes = tf.stack([bx, by, bw, bh], -1)\n",
    "    pred_conf  = tf.sigmoid(y_pred[..., 4]) # to = sig\n",
    "    pred_clf   = y_pred[..., 5:]\n",
    "\n",
    "    return pred_boxes, pred_conf, pred_clf\n",
    "    \n",
    "                           \n",
    "def _calc_iou(true_boxes, pred_boxes):\n",
    "    # Scaled anchors to size of feature map\n",
    "    output_shape   = K.shape(pred_boxes)[1:3]\n",
    "    OUTPUT_SIZE =  K.cast(K.reshape([output_shape[0], output_shape[1]], [1, 1, 1, 1, 2]), tf.float32)\n",
    "    \n",
    "    pred_xy     = pred_boxes[...,:2]    * OUTPUT_SIZE \n",
    "    pred_wh     = pred_boxes[..., 2:4]  * OUTPUT_SIZE \n",
    "    pred_area   = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    true_xy     = true_boxes[...,:2]  * OUTPUT_SIZE \n",
    "    true_wh     = true_boxes[...,2:4] * OUTPUT_SIZE \n",
    "    true_area   = true_wh[..., 0] * true_wh[..., 1]\n",
    "    \n",
    "    # Calculate IoU between ground truth and prediction\n",
    "    intersect_ul   = tf.maximum(pred_xy - 0.5 *  pred_wh, true_xy - 0.5 * true_wh)\n",
    "    intersect_br   = tf.minimum(pred_xy + 0.5 *  pred_wh, true_xy + 0.5 * true_wh)\n",
    "    intersect_wh   = tf.maximum(intersect_br - intersect_ul, 0.0)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    iou = tf.truediv(intersect_area, true_area + pred_area - intersect_area)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "    \n",
    "def _create_offset_map(output_shape):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    GRID_W    = tf.cast(output_shape[1], tf.int32)\n",
    "    GRID_H    = tf.cast(output_shape[2], tf.int32)\n",
    "    N_ANCHORS = len(ANCHORS)\n",
    "\n",
    "    cx = tf.cast((K.arange(0, stop=GRID_H)), dtype=tf.float32)\n",
    "    cx = K.expand_dims(cx, -1)\n",
    "    cx = K.tile(cx, (GRID_W, N_ANCHORS))\n",
    "    cx = K.reshape(cx, [-1, GRID_W, GRID_H, N_ANCHORS])\n",
    "\n",
    "    cy = K.cast((K.arange(0, stop=GRID_W)), dtype=tf.float32)\n",
    "    cy = K.reshape(cy, [-1, 1])\n",
    "    cy = K.tile(cy, [1, N_ANCHORS*GRID_H])  \n",
    "    cy = K.reshape(cy, [-1])    \n",
    "    cy = K.reshape(cy, [-1, GRID_W, GRID_H, N_ANCHORS])\n",
    "    \n",
    "    return cx, cy\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true: shape [BATCH, NUM_CLASSES + 5]\n",
    "    y_pred: [BATCH, OUTPUT_W, OUTPUT_H, N_ANCHORS, N_CLASSES + 5]\n",
    "    \n",
    "    y_true provides: [xc, yc, w, h, conf, class_prob]\n",
    "    y\n",
    "    \"\"\"\n",
    "    pred_shape = K.shape(y_pred)[1:3]\n",
    "\n",
    "    true_boxes, true_conf, true_cls = _process_gt(y_true, pred_shape)\n",
    "    pred_boxes, pred_conf, pred_cls = _process_prediction(y_pred)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou           = _calc_iou(true_boxes, pred_boxes)\n",
    "    best_box      = tf.equal(iou, tf.reduce_max(iou, [3], True)) \n",
    "    best_box      = tf.to_float(best_box)\n",
    "    true_conf     = tf.expand_dims(best_box * true_conf, -1)\n",
    "    pred_conf     = tf.expand_dims(pred_conf, -1)\n",
    "    \n",
    "    ### Compute the weights\n",
    "    weight_coor = 5.0 * tf.concat(4 * [true_conf], 4)\n",
    "    cls_loss = tf.pow(pred_boxes - true_boxes, 2)* weight_coor\n",
    "    \n",
    "    # Objective ness\n",
    "    weight_conf = 0.5 * (1. - true_conf) + 5.0 * true_conf\n",
    "    obj_loss = tf.pow(pred_conf - pred_conf, 2)* weight_conf\n",
    "    \n",
    "    # Clf loss\n",
    "    weight_prob = 1.0 *  tf.concat(N_CLASSES * [true_conf], 4) \n",
    "    clf_loss    = tf.pow(pred_cls - pred_cls, 2)*weight_prob\n",
    "    \n",
    "    # Total loss\n",
    "    loss = tf.concat([cls_loss, obj_loss, clf_loss], 4)\n",
    "    loss = tf.reshape(loss, [-1, 30*40*N_ANCHORS*(4 + 1 + N_CLASSES)])\n",
    "    loss = tf.reduce_sum(loss, 1)\n",
    "    loss = .5 * tf.reduce_mean(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is(are) 1 GPU(s) on device.\n",
      "Epoch 1/10\n",
      " 28/100 [=======>......................] - ETA: 150s - loss: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-aae1c1d04218>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                             \u001b[0mepochs\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                             \u001b[0mcallbacks\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_moldel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                             workers=1, verbose=1)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov2.weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1901\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import keras\n",
    "from utils.data_generator import flow_from_list\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.multi_gpu import make_parallel, get_gpus\n",
    "\n",
    "# HYPER-PARAMETERS\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS     = 5\n",
    "LEARN_RATE = 1e-5\n",
    "\n",
    "\n",
    "# Data Generator\n",
    "train_data_gen = flow_from_list(x_train, y_train, ANCHORS, batch_size=BATCH_SIZE, augment_data=True)\n",
    "\n",
    "# For Debugging purpose\n",
    "tf_board   = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=3, mode='min', verbose=1)\n",
    "save_moldel= keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch,logs: model.save_weights('yolov2-epoch%s-loss:%s.weights'%(epoch, str(logs.get('loss')))))\n",
    "\n",
    "# TRAIN ON MULTI-GPUS\n",
    "n_gpus = get_gpus()\n",
    "if n_gpus > 1:\n",
    "    BATCH_SIZE = n_gpus * BATCH_SIZE\n",
    "    model_par = make_parallel(model, n_gpus)\n",
    "else:\n",
    "    model_par = model\n",
    "\n",
    "model_par.compile(optimizer=Adam(LEARN_RATE),loss=custom_loss)\n",
    "hist =  model_par.fit_generator(generator   = train_data_gen, \n",
    "                            steps_per_epoch = 100, \n",
    "                            epochs          = 10, \n",
    "                            callbacks       = [tf_board, early_stop, save_moldel],\n",
    "                            workers=1, verbose=1)\n",
    "\n",
    "model.save_weights('yolov2.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-GPUs Training - Data Parallelism Approach\n",
    "\n",
    "* Each GPU will have a copy of the model\n",
    "* During training time, mean of all gradidents from each GPU will be calculated to update the model\n",
    "<img style=\"width:40%\" src=\"https://www.tensorflow.org/images/Parallelism.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training process using Tensorboard\n",
    "Open `http://<public-dns>:6006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def extract_sign(img, bbox, output_size=(32, 32)):\n",
    "    xc, yc, w, h = bbox.x, bbox.y, bbox.w, bbox.h\n",
    "    x1   = int(xc - w/2)\n",
    "    y1   = int(yc - h/2)\n",
    "    x2   = int(xc + w/2)\n",
    "    y2   = int(yc + h/2)\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    roi = cv2.resize(roi, output_size)\n",
    "    return roi\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "fig = plt.figure(figsize=(17, 8))\n",
    "for i, label in enumerate(labels):\n",
    "    ax           = fig.add_subplot(4, 8, 1 + i, xticks=[], yticks=[])\n",
    "    idx          = np.where(y_train[:, 1] == label)[0][0]\n",
    "    img          = cv2.cvtColor(cv2.imread(x_train[idx]), cv2.COLOR_BGR2RGB)\n",
    "    box          = y_train[idx][0]\n",
    "    sign_only    = extract_sign(img, box, (32, 32)) #  just extract the sign\n",
    "    ax.set_title(label)\n",
    "    plt.imshow(sign_only)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1.  + np.exp(-x))\n",
    "\n",
    "def interpret_netout(image, netout):\n",
    "    output_shape = K.shape(netout)\n",
    "    boxes = []\n",
    "    with sess.as_default():\n",
    "        GRID_W = tf.cast(output_shape[0], tf.int32).eval()\n",
    "        GRID_H = tf.cast(output_shape[1], tf.int32).eval()\n",
    "    \n",
    "    netout = np.reshape(netout, [GRID_W, GRID_H, len(ANCHORS), -1])\n",
    "    # interpret the output by the network\n",
    "    print(GRID_W, GRID_H)\n",
    "    print(np.shape(netout))\n",
    "    for row in range(GRID_W):\n",
    "        for col in range(GRID_H):\n",
    "            for b in range(len(ANCHORS)):\n",
    "                box = BoundBox(N_CLASSES)\n",
    "\n",
    "                # first 5 weights for x, y, w, h and confidence\n",
    "                box.x, box.y, box.w, box.h, box.c = netout[row, col, b,:5]\n",
    "                box.x = (col + sigmoid(box.x)) / GRID_W\n",
    "                box.y = (row + sigmoid(box.y)) / GRID_H\n",
    "#                 box.w = ANCHORS[b][0] * np.exp(box.w) / GRID_W\n",
    "#                 box.h = ANCHORS[b][1] * np.exp(box.h) / GRID_H\n",
    "                box.w = ANCHORS[b][0] * np.exp(box.w)\n",
    "                box.h = ANCHORS[b][1] * np.exp(box.h)\n",
    "                box.c = sigmoid(box.c)\n",
    "\n",
    "                # last  weights for class probabilities\n",
    "                classes = netout[row,col,b,5:]\n",
    "                box.probs = softmax(classes) * box.c # P(obj|class) = P(obj)*softmax(P(classes))\n",
    "                box.probs *= box.probs > THRESHOLD\n",
    "                boxes.append(box)\n",
    "\n",
    "    # suppress non-maximal boxes\n",
    "    for c in range(N_CLASSES):\n",
    "        sorted_indices = list(reversed(np.argsort([box.probs[c] for box in boxes])))\n",
    "\n",
    "        for i in xrange(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            \n",
    "            if boxes[index_i].probs[c] == 0: \n",
    "                continue\n",
    "            else:\n",
    "                for j in xrange(i+1, len(sorted_indices)):\n",
    "                    index_j = sorted_indices[j]\n",
    "                    \n",
    "                    if boxes[index_i].iou(boxes[index_j]) >= 0.4:\n",
    "                        boxes[index_j].probs[c] = 0\n",
    "\n",
    "    # draw the boxes using a threshold\n",
    "    for box in boxes:\n",
    "        max_indx = np.argmax(box.probs)\n",
    "        max_prob = box.probs[max_indx]\n",
    "        if max_prob > THRESHOLD:\n",
    "            xmin  = int((box.x - box.w/2) * image.shape[1])\n",
    "            xmax  = int((box.x + box.w/2) * image.shape[1])\n",
    "            ymin  = int((box.y - box.h/2) * image.shape[0])\n",
    "            ymax  = int((box.y + box.h/2) * image.shape[0])\n",
    "            print((xmin,ymin), (xmax,ymax))\n",
    "            print(max_indx)\n",
    "            cv2.rectangle(image, (xmin,ymin), (xmax,ymax),np.random.randint(0, 255, [3]), 3)\n",
    "            cv2.putText(image, LABELS[max_indx], (xmin, ymin - 12), 0, 1e-3 * image.shape[0], (0,255,0), 2)\n",
    "    return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
