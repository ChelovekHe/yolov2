{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train YOLOv2 on LISA Dataset\n",
    "-----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version) # Check Python Version\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.optimizers import Adam\n",
    "from utils.parse_input import load_data    # Data handler for LISA dataset\n",
    "from cfg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LISA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa_path = \"/home/ubuntu/dataset/training/\" # Remember the `/` at the end\n",
    "pretrained_path = \"/home/ubuntu/dataset/darknet19_544.weights\"\n",
    "\n",
    "\n",
    "x_train, y_train = load_data('training.txt')\n",
    "labels           = np.unique(y_train[:,1])\n",
    "num_classes      = len(labels)            # Count number of classes in the dataset\n",
    "print(\"Train: {} samples\\nNumber of classes: {}\".format(len(x_train),num_classes))\n",
    "print(\"\\nLabel Sample: \\n{}\".format(y_train[0]))\n",
    "\n",
    "ANCHORS       = np.array(((0.023717899133663362, 0.035715759075907606),\n",
    "(0.059577141608391594, 0.08738709207459215),\n",
    "(0.08816276658767774, 0.1294924960505529),\n",
    "(0.03283318210930825, 0.0483890193566751),\n",
    "(0.04450034340659346, 0.064308608058608)))\n",
    "print(\"\\n\\nRelative Anchors using K-mean clustering [K=5]\\n {}\".format(ANCHORS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def extract_sign(img, bbox, output_size=(32, 32)):\n",
    "    xc, yc, w, h = bbox.x, bbox.y, bbox.w, bbox.h\n",
    "    x1   = int(xc - w/2)\n",
    "    y1   = int(yc - h/2)\n",
    "    x2   = int(xc + w/2)\n",
    "    y2   = int(yc + h/2)\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    roi = cv2.resize(roi, output_size)\n",
    "    return roi\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "fig = plt.figure(figsize=(17, 8))\n",
    "for i, label in enumerate(labels):\n",
    "    ax           = fig.add_subplot(4, 8, 1 + i, xticks=[], yticks=[])\n",
    "    idx          = np.where(y_train[:, 1] == label)[0][0]\n",
    "    img          = cv2.cvtColor(cv2.imread(x_train[idx]), cv2.COLOR_BGR2RGB)\n",
    "    box          = y_train[idx][0]\n",
    "    sign_only    = extract_sign(img, box, (32, 32)) #  just extract the sign\n",
    "    ax.set_title(label)\n",
    "    plt.imshow(sign_only)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct YOLOv2 On Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov2.model import YOLOv2, darknet19\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session() # Avoid duplicate model\n",
    "\n",
    "darknet19 = darknet19(pretrained_path, freeze_layers=True)\n",
    "yolov2    = YOLOv2(feature_extractor=darknet19, num_anchors=len(ANCHORS), num_classes=N_CLASSES)\n",
    "model     = yolov2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    pred_shape = K.shape(y_pred)[1:3]\n",
    "    \n",
    "    GRID_W = tf.cast(pred_shape[0], tf.float32)\n",
    "    GRID_H = tf.cast(pred_shape[1], tf.float32)\n",
    "    \n",
    "    NORM_W = tf.cast(32.*GRID_W, tf.float32)\n",
    "    NORM_H = tf.cast(32.*GRID_H, tf.float32)\n",
    "    \n",
    "    no_object_scale = 0.5\n",
    "    object_scale     = 5.0\n",
    "    coordinate_scale = 1.0\n",
    "    class_scale      = 1.0\n",
    "    N_ANCHORS        = len(ANCHORS)\n",
    "\n",
    "    pred_shape = K.shape(y_pred)[1:3]\n",
    "    y_pred = K.reshape(y_pred, [-1, pred_shape[0], pred_shape[1], N_ANCHORS, N_CLASSES + 5])\n",
    "    y_true = K.reshape(y_true, [-1, pred_shape[0], pred_shape[1], N_ANCHORS, N_CLASSES + 5])\n",
    "\n",
    "    anchor_tensor = np.reshape(ANCHORS, [1, 1, 1, N_ANCHORS, 2])\n",
    "\n",
    "    #  Adjust Prediction\n",
    "    pred_box_xy   = tf.sigmoid(y_pred[:, :, :, :, :2])\n",
    "    pred_box_wh   = tf.exp(y_pred[:, :, :, :, 2:4]) * anchor_tensor\n",
    "    pred_box_wh   = tf.sqrt(pred_box_wh / K.reshape([GRID_W, GRID_H], [1, 1, 1, 1, 2]))\n",
    "    pred_box_conf = tf.expand_dims(tf.sigmoid(y_pred[:, :, :, :, 4]), -1)  # adjust confidence\n",
    "    pred_box_prob = tf.nn.softmax(y_pred[:, :, :, :, 5:])  # adjust probability\n",
    "\n",
    "    #  Adjust ground truth\n",
    "    center_xy = y_true[:, :, :, :, 0:2]\n",
    "    center_xy = center_xy / K.reshape([(NORM_W / GRID_W), (NORM_H / GRID_H)], [1, 1, 1, 1, 2])\n",
    "\n",
    "    true_box_xy = center_xy - tf.floor(center_xy)\n",
    "    true_box_wh = y_true[:, :, :, :, 2:4]\n",
    "    true_box_wh = tf.sqrt(true_box_wh / K.reshape([NORM_W, NORM_H], [1, 1, 1, 1, 2]))\n",
    "\n",
    "    # adjust confidence\n",
    "    pred_tem_wh = tf.pow(pred_box_wh, 2) * K.reshape([GRID_W, GRID_H], [1, 1, 1, 1, 2])\n",
    "    pred_box_area = pred_tem_wh[:, :, :, :, 0] * pred_tem_wh[:, :, :, :, 1]\n",
    "    pred_box_ul = pred_box_xy - 0.5 * pred_tem_wh\n",
    "    pred_box_bd = pred_box_xy + 0.5 * pred_tem_wh\n",
    "\n",
    "    true_tem_wh = tf.pow(true_box_wh, 2) * K.reshape([GRID_W, GRID_H], [1, 1, 1, 1, 2])\n",
    "    true_box_area = true_tem_wh[:, :, :, :, 0] * true_tem_wh[:, :, :, :, 1]\n",
    "    true_box_ul = true_box_xy - 0.5 * true_tem_wh\n",
    "    true_box_bd = true_box_xy + 0.5 * true_tem_wh\n",
    "\n",
    "    # Calculate IoU between ground truth and prediction\n",
    "    intersect_ul = tf.maximum(pred_box_ul, true_box_ul)\n",
    "    intersect_br = tf.minimum(pred_box_bd, true_box_bd)\n",
    "    intersect_wh = intersect_br - intersect_ul\n",
    "    intersect_wh = tf.maximum(intersect_wh, 0.0)\n",
    "    intersect_area = intersect_wh[:, :, :, :, 0] * intersect_wh[:, :, :, :, 1]\n",
    "\n",
    "    iou = tf.truediv(intersect_area, true_box_area + pred_box_area - intersect_area)\n",
    "    best_box = tf.equal(iou, tf.reduce_max(iou, [3], True))\n",
    "    best_box = tf.to_float(best_box)\n",
    "    # calculate avg_iou here\n",
    "\n",
    "    true_box_conf = tf.expand_dims(best_box * y_true[:, :, :, :, 4], -1)\n",
    "    true_box_prob = y_true[:, :, :, :, 5:]  # adjust confidence\n",
    "\n",
    "    y_pred = tf.concat([pred_box_xy, pred_box_wh, pred_box_conf, pred_box_prob], 4)\n",
    "    y_true = tf.concat([true_box_xy, true_box_wh, true_box_conf, true_box_prob], 4)\n",
    "\n",
    "    # Compute the weights\n",
    "\n",
    "    # Object Confidence Loss\n",
    "    weight_conf = no_object_scale * (1. - true_box_conf) + object_scale * true_box_conf\n",
    "\n",
    "    # Object Localization Loss\n",
    "    weight_coor = tf.concat(4 * [true_box_conf], 4)\n",
    "    weight_coor = coordinate_scale * weight_coor\n",
    "\n",
    "    # Object Classification Loss\n",
    "    weight_prob = tf.concat(N_CLASSES * [true_box_conf], 4)\n",
    "    weight_prob = class_scale * weight_prob\n",
    "\n",
    "    # Total Loss\n",
    "    weight = tf.concat([weight_coor, weight_conf, weight_prob], 4)\n",
    "\n",
    "    # ## Finalize the loss\n",
    "    loss = tf.pow(y_pred - y_true, 2)\n",
    "    loss = loss * weight\n",
    "    loss = tf.reshape(loss, [-1, tf.cast(GRID_W * GRID_H * N_ANCHORS * (4 + 1 + N_CLASSES), tf.int32)])\n",
    "    loss = tf.reduce_sum(loss, 1)\n",
    "    loss = .5 * tf.reduce_mean(loss)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import keras\n",
    "from utils.data_generator import flow_from_list\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.multi_gpu import make_parallel, get_gpus\n",
    "\n",
    "# HYPER-PARAMETERS\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS     = 5\n",
    "LEARN_RATE = 1e-5\n",
    "\n",
    "\n",
    "# Data Generator\n",
    "train_data_gen = flow_from_list(x_train, y_train, ANCHORS, batch_size=BATCH_SIZE, augment_data=True)\n",
    "\n",
    "# For Debugging purpose\n",
    "tf_board = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "check_pt = keras.callbacks.ModelCheckpoint('models/weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                                           verbose=0, save_best_only=False, \n",
    "                                           save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# TRAIN ON MULTI-GPUS\n",
    "n_gpus = get_gpus()\n",
    "if n_gpus > 1:\n",
    "    BATCH_SIZE = n_gpus * BATCH_SIZE\n",
    "    model = make_parallel(model, n_gpus)\n",
    "\n",
    "model.compile(optimizer=Adam(LEARN_RATE),loss=custom_loss)\n",
    "hist =  model.fit_generator(generator       = train_data_gen, \n",
    "                            steps_per_epoch = 2*len(x_train) / BATCH_SIZE, \n",
    "                            epochs          = EPOCHS, \n",
    "                            callbacks       = [tf_board, check_pt],\n",
    "                            workers=1, verbose=1)\n",
    "\n",
    "model.save_weights('yolov2.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-GPUs Training - Data Parallelism Approach\n",
    "\n",
    "* Each GPU will have a copy of the model\n",
    "* During training time, mean of all gradidents from each GPU will be calculated to update the model\n",
    "<img style=\"width:40%\" src=\"https://www.tensorflow.org/images/Parallelism.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training process using Tensorboard\n",
    "Open `http://<public-dns>:6006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.utils import shuffle\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# def extract_sign(img, bbox, output_size=(32, 32)):\n",
    "#     xc, yc, w, h = bbox.x, bbox.y, bbox.w, bbox.h\n",
    "#     x1   = int(xc - w/2)\n",
    "#     y1   = int(yc - h/2)\n",
    "#     x2   = int(xc + w/2)\n",
    "#     y2   = int(yc + h/2)\n",
    "#     roi = img[y1:y2, x1:x2]\n",
    "#     roi = cv2.resize(roi, output_size)\n",
    "#     return roi\n",
    "# x_train, y_train = shuffle(x_train, y_train)\n",
    "# fig = plt.figure(figsize=(17, 8))\n",
    "# for i, label in enumerate(labels):\n",
    "#     ax           = fig.add_subplot(4, 8, 1 + i, xticks=[], yticks=[])\n",
    "#     idx          = np.where(y_train[:, 1] == label)[0][0]\n",
    "#     img          = cv2.cvtColor(cv2.imread(x_train[idx]), cv2.COLOR_BGR2RGB)\n",
    "#     box          = y_train[idx][0]\n",
    "#     sign_only    = extract_sign(img, box, (32, 32)) #  just extract the sign\n",
    "#     ax.set_title(label)\n",
    "#     plt.imshow(sign_only)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Count frequencies of each traffic sign\n",
    "# labels, frequencies = np.unique(y_train[:,1 ], return_counts=True)\n",
    "\n",
    "# plt.figure(figsize=(20, 5))\n",
    "# x = np.arange(len(labels))\n",
    "# plt.xticks(x, labels, rotation=70)\n",
    "# plt.bar(x, frequencies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
