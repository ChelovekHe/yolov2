{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.image_handler import preprocess_img\n",
    "%matplotlib inline\n",
    "\n",
    "img = cv2.cvtColor(cv2.imread('./test_images/stop_1405106680.avi_image9.png'), cv2.COLOR_BGR2RGB)\n",
    "# img = cv2.cvtColor(cv2.imread('./test_images/stop.jpg'), cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (int(1280/2),int(960/2)))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "# dog    = Box(70, 258, 209, 356, 'Dog', 0.79)\n",
    "# person = Box(190, 98, 271, 379, 'Person', 0.81)\n",
    "# horse  = Box(399, 128, 605, 352, 'Horse', 0.89)\n",
    "# boxes = [dog, person, horse]\n",
    "class Box():\n",
    "    def __init__(self, x1, y1, x2, y2, label, score):\n",
    "        self.x1 = int(x1)\n",
    "        self.x2 = int(x2)\n",
    "        self.y1 = int(y1)\n",
    "        self.y2 = int(y2)\n",
    "        self.cls = str(label)\n",
    "        self.score = float(score)\n",
    "\n",
    "        \n",
    "def draw(img, boxes, color=[0, 255, 0], thickness=1):\n",
    "    result = np.copy(img)\n",
    "    \n",
    "    for box in boxes:\n",
    "        p1 = (box.x1, box.y1)\n",
    "        p2 = (box.x2, box.y2)\n",
    "        result = cv2.rectangle(result, p1, p2, color=(0, 255, 0), thickness=thickness)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.regularizers import l2\n",
    "from cfg import *\n",
    "from model.yolov2 import YOLOv2, darknet19\n",
    "\n",
    "K.clear_session()  # to avoid duplicating model\n",
    "THRESHOLD = 0.7 \n",
    "# N_CLASSES = 80\n",
    "# ANCHORS   = np.array(((0.57273, 0.677385), (1.87446, 2.06253), \n",
    "#                       (3.33843, 5.47434), (7.88282, 3.52778), (9.77052, 9.16828)))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    yolov2 = YOLOv2(feature_extractor=darknet19(input_size=(None, None, 3)), num_anchors=N_ANCHORS, num_classes=N_CLASSES)\n",
    "    model = yolov2.model\n",
    "    model.load_weights('../backup/yolov2-epoch9-loss3.57268298149.weights')\n",
    "#     model.load_weights('../yolo-coco.h5')\n",
    "\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input\n",
    "input_img = img / 255. \n",
    "input_img = np.expand_dims(input_img, 0)\n",
    "\n",
    "# Making prediction\n",
    "netout = model.predict(input_img)\n",
    "\n",
    "netshape = np.shape(netout)\n",
    "netout = np.reshape(netout, [-1, netshape[1], netshape[2], 5, N_CLASSES+5])\n",
    "\n",
    "GRID_H, GRID_W = netout.shape[1:3]\n",
    "height, width ,c  = img.shape\n",
    "print(np.shape(netout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_shape = img.shape\n",
    "ANCHORS = ANCHORS * np.array([GRID_W, GRID_H]) / 2.0\n",
    "# Create GRID-cell map\n",
    "cx = tf.cast((K.arange(0, stop=GRID_W)), dtype=tf.float32)\n",
    "cx = K.tile(cx, [GRID_H])\n",
    "cx = K.reshape(cx, [-1, GRID_H, GRID_W, 1])\n",
    "\n",
    "cy = K.cast((K.arange(0, stop=GRID_H)), dtype=tf.float32)\n",
    "cy = K.reshape(cy, [-1, 1])\n",
    "cy = K.tile(cy, [1, GRID_W])  \n",
    "cy = K.reshape(cy, [-1])    \n",
    "cy = K.reshape(cy, [-1, GRID_H, GRID_W, 1])\n",
    "\n",
    "c_xy = tf.stack([cx, cy], -1)\n",
    "c_xy = K.cast(c_xy, K.dtype(netout))\n",
    "\n",
    "\n",
    "anchors_tensor = tf.cast(K.reshape(K.variable(ANCHORS), [1, 1, 1, 5, 2]), tf.float32)\n",
    "netout_size   = K.cast(K.reshape([GRID_W, GRID_H], [1, 1, 1, 1, 2]), K.dtype(netout))\n",
    "\n",
    "box_xy          = K.sigmoid(netout[..., :2])\n",
    "box_wh          = K.exp(netout[..., 2:4])\n",
    "box_confidence  = K.sigmoid(netout[..., 4:5])\n",
    "box_class_probs = K.softmax(netout[..., 5:])\n",
    "\n",
    "# Adjust predictions to each spatial grid point and anchor size.\n",
    "box_xy = (box_xy + c_xy) / netout_size\n",
    "box_wh = box_wh * anchors_tensor / netout_size\n",
    "box_mins  = box_xy - (box_wh / 2.)\n",
    "box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "# Y1, X1, Y2, X2\n",
    "boxes   = K.concatenate([box_mins[..., 1:2], box_mins[..., 0:1],  box_maxes[..., 1:2], box_maxes[..., 0:1]])\n",
    "\n",
    "box_scores       = box_confidence * box_class_probs\n",
    "box_classes      = K.argmax(box_scores, -1)\n",
    "box_class_scores = K.max(box_scores, -1)\n",
    "prediction_mask  = (box_class_scores >= 0.1)\n",
    "\n",
    "boxes   = tf.boolean_mask(boxes, prediction_mask)\n",
    "scores  = tf.boolean_mask(box_class_scores, prediction_mask)\n",
    "classes = tf.boolean_mask(box_classes, prediction_mask)\n",
    "\n",
    "# Scale boxes back to original image shape.\n",
    "height = image_shape[0]\n",
    "width = image_shape[1]\n",
    "\n",
    "image_dims = tf.cast(K.stack([height, width, height, width]), tf.float32)\n",
    "image_dims = K.reshape(image_dims, [1, 4])\n",
    "boxes = boxes * image_dims\n",
    "\n",
    "nms_index = tf.image.non_max_suppression(boxes, scores, tf.Variable(10), iou_threshold=0.6)\n",
    "boxes = K.gather(boxes, nms_index)\n",
    "scores = K.gather(scores, nms_index)\n",
    "classes = K.gather(classes, nms_index)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:   \n",
    "    tf.global_variables_initializer().run()\n",
    "#     obj_score = box_scores.eval()\n",
    "#     print(obj_score[obj_score > 0.01])\n",
    "    boxes_prediction = boxes.eval()\n",
    "    scores_prediction = scores.eval()\n",
    "    classes_prediction = classes.eval()\n",
    "\n",
    "print(boxes_prediction, scores_prediction, classes_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = boxes_prediction\n",
    "\n",
    "bboxes = []\n",
    "for box, score, cls in zip(result, scores_prediction, classes_prediction):\n",
    "    y1, x1, y2, x2 = box.astype(np.int)\n",
    "    bboxes.append(Box(x1, y1, x2, y2, cls, score))\n",
    "\n",
    "result = draw(img, bboxes)\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.imshow(result)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3",
   "language": "python",
   "name": "yad2k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
