{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning YOLOv2 on LISA Dataset\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "* What is Transfer learning\n",
    "* Relationship between COCO and LISA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.13 |Anaconda 4.4.0 (64-bit)| (default, Dec 20 2016, 23:09:15) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version) # Check Python Version\n",
    "import os\n",
    "from keras.optimizers import Adam\n",
    "from cfg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LISA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ground truth boxes: 3672 boxes\n",
      "Train: 3672 samples\n",
      "Number of classes: 31\n",
      "\n",
      "Label Sample: \n",
      "[1093.5 408.0 45.0 48.0 'doNotEnter']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.parse_input import load_data    # Data handler for LISA dataset\n",
    "\n",
    "x_train, y_train = load_data('training.txt')\n",
    "labels           = np.unique(y_train[:,1])\n",
    "num_classes      = len(labels)            # Count number of classes in the dataset\n",
    "\n",
    "print(\"Train: {} samples\\nNumber of classes: {}\".format(len(x_train),num_classes))\n",
    "print(\"\\nLabel Sample: \\n{}\".format(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained YOLOv2 on COCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, None, None, 32 864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, None, None, 32 128         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)        (None, None, None, 32 0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, None, None, 32 0           leaky_re_lu_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, None, None, 64 18432       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, None, None, 64 256         conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)        (None, None, None, 64 0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 64 0           leaky_re_lu_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, None, None, 12 73728       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, None, None, 12 512         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)        (None, None, None, 12 0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, None, None, 64 8192        leaky_re_lu_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, None, None, 64 256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)        (None, None, None, 64 0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, None, None, 12 73728       leaky_re_lu_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, None, None, 12 512         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)        (None, None, None, 12 0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, None, None, 12 0           leaky_re_lu_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, None, None, 25 294912      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, None, None, 25 1024        conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)        (None, None, None, 25 0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, None, None, 12 32768       leaky_re_lu_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, None, None, 12 512         conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)        (None, None, None, 12 0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, None, None, 25 294912      leaky_re_lu_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, None, None, 25 1024        conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)        (None, None, None, 25 0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, None, None, 25 0           leaky_re_lu_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, None, None, 51 1179648     max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, None, None, 51 2048        conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)        (None, None, None, 51 0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, None, None, 25 131072      leaky_re_lu_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, None, None, 25 1024        conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)       (None, None, None, 25 0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, None, None, 51 1179648     leaky_re_lu_10[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, None, None, 51 2048        conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)       (None, None, None, 51 0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, None, None, 25 131072      leaky_re_lu_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, None, None, 25 1024        conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)       (None, None, None, 25 0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, None, None, 51 1179648     leaky_re_lu_12[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, None, None, 51 2048        conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)       (None, None, None, 51 0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, None, None, 51 0           leaky_re_lu_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, None, None, 10 4718592     max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, None, None, 10 4096        conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, None, None, 51 524288      leaky_re_lu_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, None, None, 51 2048        conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)       (None, None, None, 51 0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, None, None, 10 4718592     leaky_re_lu_15[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, None, None, 10 4096        conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, None, None, 51 524288      leaky_re_lu_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, None, None, 51 2048        conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)       (None, None, None, 51 0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, None, None, 10 4718592     leaky_re_lu_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, None, None, 10 4096        conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, None, None, 10 9437184     leaky_re_lu_18[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, None, None, 10 4096        conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, None, None, 64 32768       leaky_re_lu_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, None, None, 64 256         conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, None, None, 10 9437184     leaky_re_lu_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)       (None, None, None, 64 0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, None, None, 10 4096        conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "space_to_depth (Lambda)          (None, None, None, 25 0           leaky_re_lu_21[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, None, None, 12 0           space_to_depth[0][0]             \n",
      "                                                                   leaky_re_lu_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, None, None, 10 11796480    concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, None, None, 10 4096        conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, None, None, 42 435625      leaky_re_lu_22[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 50,983,561\n",
      "Trainable params: 31,145,513\n",
      "Non-trainable params: 19,838,048\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from model.yolov2 import YOLOv2, darknet19\n",
    "import keras.backend as K\n",
    "K.clear_session() # Avoid duplicate model \n",
    "\n",
    "# Original YOLOv2 - Trained on COCO Dataset\n",
    "darknet19 = darknet19(freeze_layers=True)\n",
    "yolov2    = YOLOv2(feature_extractor=darknet19, num_anchors=5, num_classes=80)\n",
    "yolov2.model.load_weights('../yolo-coco.h5')\n",
    "yolov2.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning - Cut last layer and create a new Conv2D for Traffic Sign Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, None, None, 32 864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, None, None, 32 128         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)        (None, None, None, 32 0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, None, None, 32 0           leaky_re_lu_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, None, None, 64 18432       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, None, None, 64 256         conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)        (None, None, None, 64 0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 64 0           leaky_re_lu_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, None, None, 12 73728       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, None, None, 12 512         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)        (None, None, None, 12 0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, None, None, 64 8192        leaky_re_lu_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, None, None, 64 256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)        (None, None, None, 64 0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, None, None, 12 73728       leaky_re_lu_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, None, None, 12 512         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)        (None, None, None, 12 0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, None, None, 12 0           leaky_re_lu_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, None, None, 25 294912      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, None, None, 25 1024        conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)        (None, None, None, 25 0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, None, None, 12 32768       leaky_re_lu_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, None, None, 12 512         conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)        (None, None, None, 12 0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, None, None, 25 294912      leaky_re_lu_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, None, None, 25 1024        conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)        (None, None, None, 25 0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, None, None, 25 0           leaky_re_lu_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, None, None, 51 1179648     max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, None, None, 51 2048        conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)        (None, None, None, 51 0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, None, None, 25 131072      leaky_re_lu_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, None, None, 25 1024        conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)       (None, None, None, 25 0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, None, None, 51 1179648     leaky_re_lu_10[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, None, None, 51 2048        conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)       (None, None, None, 51 0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, None, None, 25 131072      leaky_re_lu_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, None, None, 25 1024        conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)       (None, None, None, 25 0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, None, None, 51 1179648     leaky_re_lu_12[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, None, None, 51 2048        conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)       (None, None, None, 51 0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, None, None, 51 0           leaky_re_lu_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, None, None, 10 4718592     max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, None, None, 10 4096        conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, None, None, 51 524288      leaky_re_lu_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, None, None, 51 2048        conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)       (None, None, None, 51 0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, None, None, 10 4718592     leaky_re_lu_15[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, None, None, 10 4096        conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, None, None, 51 524288      leaky_re_lu_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, None, None, 51 2048        conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)       (None, None, None, 51 0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, None, None, 10 4718592     leaky_re_lu_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, None, None, 10 4096        conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, None, None, 10 9437184     leaky_re_lu_18[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, None, None, 10 4096        conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, None, None, 64 32768       leaky_re_lu_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, None, None, 64 256         conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, None, None, 10 9437184     leaky_re_lu_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)       (None, None, None, 64 0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, None, None, 10 4096        conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "space_to_depth (Lambda)          (None, None, None, 25 0           leaky_re_lu_21[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, None, None, 12 0           space_to_depth[0][0]             \n",
      "                                                                   leaky_re_lu_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, None, None, 10 11796480    concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, None, None, 10 4096        conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)       (None, None, None, 10 0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, None, None, 51 4719104     leaky_re_lu_22[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "yolov2 (Conv2D)                  (None, None, None, 18 92340       conv2d_24[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 55,359,380\n",
      "Trainable params: 35,521,332\n",
      "Non-trainable params: 19,838,048\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Cut last layer\n",
    "topless_model = yolov2.model.layers[-2].output   \n",
    "\n",
    "# dd a few new Conv2D layers for Traffic Sign Detection\n",
    "traffic_sign_detector = Conv2D(filters=512,padding='same',\n",
    "                               kernel_size=(3, 3), \n",
    "                               kernel_initializer='he_uniform',\n",
    "                               activation='relu')(topless_model)\n",
    "\n",
    "traffic_sign_detector = Conv2D(filters=(N_ANCHORS* (N_CLASSES + 5)),\n",
    "                               kernel_size=(1, 1), \n",
    "                               kernel_regularizer=l2(5e-4), \n",
    "                               kernel_initializer='he_uniform', activation='linear',\n",
    "                               name='yolov2')(traffic_sign_detector)\n",
    "\n",
    "# Build a new Model for training\n",
    "model = Model(yolov2.model.input, traffic_sign_detector)\n",
    "\n",
    "#   # # Freeze lower layers\n",
    "for layer in yolov2.model.layers[:-16]:\n",
    "    layer.trainable = False\n",
    "      \n",
    "model.summary()\n",
    "# for l in model.layers:\n",
    "#     print(l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    SCALE_NOOB, SCALE_CONF, SCALE_COOR, SCALE_PROB = 0.5, 5.0, 5.0, 1.0\n",
    "    pred_shape = K.shape(y_pred)[1:3]\n",
    "    gt_shape   = K.shape(y_true)                 # shape of ground truth value\n",
    "    GRID_H = tf.cast(pred_shape[0], tf.int32)  # shape of output feature map\n",
    "    GRID_W = tf.cast(pred_shape[1], tf.int32)\n",
    "    \n",
    "    output_size = tf.cast(tf.reshape([GRID_W, GRID_H], [1,1,1,1,2]), tf.float32)\n",
    "    y_pred = tf.reshape(y_pred,[-1, pred_shape[0], pred_shape[1], N_ANCHORS, N_CLASSES +5])\n",
    "    y_true = tf.reshape(y_true,[-1, gt_shape[1], gt_shape[2], N_ANCHORS, N_CLASSES + 5])\n",
    "\n",
    "    c_xy = _create_offset_map(K.shape(y_pred))\n",
    "    \n",
    "    pred_box_xy = (tf.sigmoid(y_pred[:,:,:,:,:2]) + c_xy)  / output_size\n",
    "    pred_box_wh = tf.exp(y_pred[:,:,:,:,2:4]) * np.reshape(ANCHORS, [1,1,1,N_ANCHORS,2])\n",
    "    pred_box_wh = tf.sqrt(pred_box_wh / output_size)\n",
    "    \n",
    "    # adjust confidence\n",
    "    pred_box_conf = tf.expand_dims(tf.sigmoid(y_pred[:, :, :, :, 4]), -1) \n",
    "    # adjust probability\n",
    "    pred_box_prob = tf.nn.softmax(y_pred[:, :, :, :, 5:])\n",
    "    \n",
    "    y_pred = tf.concat([pred_box_xy, pred_box_wh, pred_box_conf, pred_box_prob], 4)\n",
    "    \n",
    "    ### Adjust ground truth\n",
    "    center_xy = y_true[:,:,:,:,0:2]\n",
    "    true_box_xy = center_xy \n",
    "    true_box_wh = tf.sqrt(y_true[:,:,:,:,2:4])\n",
    "    \n",
    "    # adjust confidence\n",
    "    pred_tem_wh = tf.pow(pred_box_wh, 2) *  output_size\n",
    "    pred_box_area = pred_tem_wh[:,:,:,:,0] * pred_tem_wh[:,:,:,:,1]\n",
    "    pred_box_ul = pred_box_xy - 0.5 * pred_tem_wh\n",
    "    pred_box_bd = pred_box_xy + 0.5 * pred_tem_wh\n",
    "    \n",
    "    true_tem_wh = tf.pow(true_box_wh, 2) *  output_size\n",
    "    true_box_area = true_tem_wh[:,:,:,:,0] * true_tem_wh[:,:,:,:,1]\n",
    "    true_box_ul = true_box_xy - 0.5 * true_tem_wh\n",
    "    true_box_bd = true_box_xy + 0.5 * true_tem_wh\n",
    "    \n",
    "    intersect_ul = tf.maximum(pred_box_ul, true_box_ul) \n",
    "    intersect_br = tf.minimum(pred_box_bd, true_box_bd)\n",
    "    intersect_wh = intersect_br - intersect_ul\n",
    "    intersect_wh = tf.maximum(intersect_wh, 0.0)\n",
    "    intersect_area = intersect_wh[:,:,:,:,0] * intersect_wh[:,:,:,:,1]\n",
    "    \n",
    "    iou = tf.truediv(intersect_area, true_box_area + pred_box_area - intersect_area)\n",
    "    best_box = tf.equal(iou, tf.reduce_max(iou, [3], True)) \n",
    "    best_box = tf.to_float(best_box)\n",
    "    true_box_conf = tf.expand_dims(best_box * y_true[:,:,:,:,4], -1)\n",
    "    \n",
    "    # adjust confidence\n",
    "    true_box_prob = y_true[:,:,:,:,5:]\n",
    "    \n",
    "    y_true = tf.concat([true_box_xy, true_box_wh, true_box_conf, true_box_prob], 4)\n",
    "    \n",
    "    ### Compute the weights\n",
    "    weight_coor = tf.concat(4 * [true_box_conf], 4)\n",
    "    weight_coor = SCALE_COOR * weight_coor\n",
    "    weight_conf = SCALE_NOOB * (1. - true_box_conf) + SCALE_CONF * true_box_conf\n",
    "    weight_prob = tf.concat(N_CLASSES * [true_box_conf], 4) \n",
    "    weight_prob = SCALE_PROB * weight_prob \n",
    "    \n",
    "    weight = tf.concat([weight_coor, weight_conf, weight_prob], 4)\n",
    "    \n",
    "    ### Finalize the loss\n",
    "    loss = tf.pow(y_pred - y_true, 2)\n",
    "    loss = loss * weight                     \n",
    "    total_loss = tf.reshape(loss, [-1, tf.cast(GRID_W*GRID_H, tf.int32)*N_ANCHORS*(4 + 1 + N_CLASSES)])\n",
    "    total_loss = tf.reduce_sum(total_loss, 1)\n",
    "    total_loss = .5 * tf.reduce_mean(total_loss)\n",
    "    \n",
    "    # @TODO update scalar loss\n",
    "    localization_loss =  tf.reduce_mean(tf.reduce_sum(loss[..., 0]))\n",
    "    confidence_loss   =  tf.reduce_mean(tf.reduce_sum(loss[..., 1]))\n",
    "    classification_loss =tf.reduce_mean(tf.reduce_sum(loss[..., 2]))\n",
    "                                        \n",
    "    tf.summary.scalar('average_iou', tf.reduce_mean(tf.reduce_sum(iou)))\n",
    "    tf.summary.scalar('localization_loss', localization_loss)\n",
    "    tf.summary.scalar('confidence_loss', confidence_loss)\n",
    "    tf.summary.scalar('classification_loss', classification_loss)\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def _create_offset_map(output_shape):\n",
    "    \"\"\"\n",
    "    In Yolo9000 paper, grid map\n",
    "    \"\"\"\n",
    "    GRID_H = tf.cast(output_shape[1], tf.int32)  # shape of output feature map\n",
    "    GRID_W = tf.cast(output_shape[2], tf.int32)\n",
    "    \n",
    "    cx = tf.cast((K.arange(0, stop=GRID_W)), dtype=tf.float32)\n",
    "    cx = K.tile(cx, [GRID_H])\n",
    "    cx = K.reshape(cx, [-1, GRID_H, GRID_W, 1])\n",
    "\n",
    "    cy = K.cast((K.arange(0, stop=GRID_H)), dtype=tf.float32)\n",
    "    cy = K.reshape(cy, [-1, 1])\n",
    "    cy = K.tile(cy, [1, GRID_W])  \n",
    "    cy = K.reshape(cy, [-1])    \n",
    "    cy = K.reshape(cy, [-1, GRID_H, GRID_W, 1])\n",
    "\n",
    "    c_xy = tf.stack([cx, cy], -1)\n",
    "    c_xy = K.cast(c_xy, tf.float32)\n",
    "\n",
    "    return c_xy\n",
    "\n",
    "def avg_iou(y_true, y_pred):\n",
    "    pred_shape = K.shape(y_pred)[1:3]\n",
    "    gt_shape   = K.shape(y_true)                 # shape of ground truth value\n",
    "    GRID_H = tf.cast(pred_shape[0], tf.int32)  # shape of output feature map\n",
    "    GRID_W = tf.cast(pred_shape[1], tf.int32)\n",
    "    \n",
    "    output_size = tf.cast(tf.reshape([GRID_W, GRID_H], [1,1,1,1,2]), tf.float32)\n",
    "    y_pred = tf.reshape(y_pred,[-1, pred_shape[0], pred_shape[1], N_ANCHORS, N_CLASSES +5])\n",
    "    y_true = tf.reshape(y_true,[-1, gt_shape[1], gt_shape[2], N_ANCHORS, N_CLASSES + 5])\n",
    "\n",
    "    c_xy = _create_offset_map(K.shape(y_pred))\n",
    "    \n",
    "    pred_box_xy = (tf.sigmoid(y_pred[:,:,:,:,:2]) + c_xy)  / output_size\n",
    "    pred_box_wh = tf.exp(y_pred[:,:,:,:,2:4]) * np.reshape(ANCHORS, [1,1,1,N_ANCHORS,2])\n",
    "    pred_box_wh = tf.sqrt(pred_box_wh / output_size)\n",
    "    \n",
    "    # adjust confidence\n",
    "    pred_box_conf = tf.expand_dims(tf.sigmoid(y_pred[:, :, :, :, 4]), -1) \n",
    "    # adjust probability\n",
    "    pred_box_prob = tf.nn.softmax(y_pred[:, :, :, :, 5:])\n",
    "    \n",
    "    y_pred = tf.concat([pred_box_xy, pred_box_wh, pred_box_conf, pred_box_prob], 4)\n",
    "    \n",
    "    ### Adjust ground truth\n",
    "    center_xy = y_true[:,:,:,:,0:2]\n",
    "    true_box_xy = center_xy \n",
    "    true_box_wh = tf.sqrt(y_true[:,:,:,:,2:4])\n",
    "    \n",
    "    # adjust confidence\n",
    "    pred_tem_wh = tf.pow(pred_box_wh, 2) *  output_size\n",
    "    pred_box_area = pred_tem_wh[:,:,:,:,0] * pred_tem_wh[:,:,:,:,1]\n",
    "    pred_box_ul = pred_box_xy - 0.5 * pred_tem_wh\n",
    "    pred_box_bd = pred_box_xy + 0.5 * pred_tem_wh\n",
    "    \n",
    "    true_tem_wh = tf.pow(true_box_wh, 2) *  output_size\n",
    "    true_box_area = true_tem_wh[:,:,:,:,0] * true_tem_wh[:,:,:,:,1]\n",
    "    true_box_ul = true_box_xy - 0.5 * true_tem_wh\n",
    "    true_box_bd = true_box_xy + 0.5 * true_tem_wh\n",
    "    \n",
    "    intersect_ul = tf.maximum(pred_box_ul, true_box_ul) \n",
    "    intersect_br = tf.minimum(pred_box_bd, true_box_bd)\n",
    "    intersect_wh = intersect_br - intersect_ul\n",
    "    intersect_wh = tf.maximum(intersect_wh, 0.0)\n",
    "    intersect_area = intersect_wh[:,:,:,:,0] * intersect_wh[:,:,:,:,1]\n",
    "    \n",
    "    iou = tf.truediv(intersect_area, true_box_area + pred_box_area - intersect_area)\n",
    "    \n",
    "    return tf.reduce_sum(iou) / tf.to_float(gt_shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# over fitting on 1 iamge\n",
    "from sklearn.utils import shuffle\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['signalAhead_1405107045', 'speedLimit50_1405372499', 'keepRight_1405359763', 'stop_1398993494', 'speedLimit30_1405371806', 'speedLimit25_1404948650', 'curveRight_1398812169', 'stop_1404942178', 'noUTurn_1405359264', 'signalAhead_1405111415', 'signalAhead_1405107045', 'speedLimit50_1405372499', 'keepRight_1405359763', 'stop_1398993494', 'speedLimit30_1405371806', 'speedLimit25_1404948650', 'curveRight_1398812169', 'stop_1404942178', 'noUTurn_1405359264', 'signalAhead_1405111415']\n",
      "[[964.5 463.0 47.0 50.0 'signalAhead']\n",
      " [370.0 450.0 32.0 42.0 'speedLimit50']\n",
      " [442.5 520.0 17.0 24.0 'keepRight']\n",
      " [1105.0 285.5 180.0 169.0 'stop']\n",
      " [958.5 435.0 25.0 38.0 'speedLimit30']\n",
      " [933.0 465.0 34.0 42.0 'speedLimit25']\n",
      " [802.5 466.5 27.0 25.0 'speedLimit35']\n",
      " [948.5 461.5 47.0 53.0 'stop']\n",
      " [1150.5 416.5 37.0 39.0 'noUTurn']\n",
      " [849.0 428.5 60.0 61.0 'signalAhead']\n",
      " [964.5 463.0 47.0 50.0 'signalAhead']\n",
      " [370.0 450.0 32.0 42.0 'speedLimit50']\n",
      " [442.5 520.0 17.0 24.0 'keepRight']\n",
      " [1105.0 285.5 180.0 169.0 'stop']\n",
      " [958.5 435.0 25.0 38.0 'speedLimit30']\n",
      " [933.0 465.0 34.0 42.0 'speedLimit25']\n",
      " [802.5 466.5 27.0 25.0 'speedLimit35']\n",
      " [948.5 461.5 47.0 53.0 'stop']\n",
      " [1150.5 416.5 37.0 39.0 'noUTurn']\n",
      " [849.0 428.5 60.0 61.0 'signalAhead']]\n",
      "/home/ubuntu/dataset/lisa/training/2014-05-01_17-03/2/frameAnnotations-2.avi_annotations/speedLimit25_1404948650.avi_image0.png\n"
     ]
    }
   ],
   "source": [
    "one_sample = np.tile(x_train[0:10], 2).tolist()\n",
    "one_label  = np.tile(y_train[0:10], [2, 1])\n",
    "print([name.split('/')[-1].split('.')[0] for name in one_sample])\n",
    "print(one_label)\n",
    "print(one_sample[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from utils.multi_gpu import make_parallel, get_gpus\n",
    "from utils.data_generator import flow_from_list\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # HYPER-PARAMETERS\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS     = 1\n",
    "LEARN_RATE = 0.0001 # this model has been pre-trained, LOWER LR is needed\n",
    "\n",
    "# Data Generator\n",
    "train_data_gen = flow_from_list(one_sample,one_label, batch_size=BATCH_SIZE, augment_data=True)\n",
    "val_data_gen = flow_from_list(one_sample,one_label, batch_size=BATCH_SIZE, augment_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is(are) 1 GPU(s) on device.\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 10s - loss: 40.3352 - avg_iou: 0.8715 - val_loss: 3.2683 - val_avg_iou: 0.9353\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 6s - loss: 2.9651 - avg_iou: 1.0881 - val_loss: 2.5635 - val_avg_iou: 1.1127\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 6s - loss: 2.2156 - avg_iou: 1.1629 - val_loss: 2.8284 - val_avg_iou: 1.0292\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 6s - loss: 2.4552 - avg_iou: 0.9283 - val_loss: 2.6072 - val_avg_iou: 1.1954\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 6s - loss: 1.5405 - avg_iou: 1.2168 - val_loss: 2.1893 - val_avg_iou: 1.2450\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 6s - loss: 2.1339 - avg_iou: 1.0827 - val_loss: 1.8602 - val_avg_iou: 1.1817\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 6s - loss: 1.6794 - avg_iou: 1.0985 - val_loss: 1.2749 - val_avg_iou: 1.2000\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 6s - loss: 1.5372 - avg_iou: 1.1452 - val_loss: 1.7310 - val_avg_iou: 1.2807\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 6s - loss: 1.0836 - avg_iou: 1.3744 - val_loss: 2.1150 - val_avg_iou: 1.3111\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 6s - loss: 1.0695 - avg_iou: 1.3067 - val_loss: 1.8238 - val_avg_iou: 1.3922\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 6s - loss: 1.1308 - avg_iou: 1.3432 - val_loss: 1.6955 - val_avg_iou: 1.2974\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 6s - loss: 2.0236 - avg_iou: 1.3174 - val_loss: 1.5629 - val_avg_iou: 1.2459\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 6s - loss: 2.1585 - avg_iou: 0.8161 - val_loss: 1.8483 - val_avg_iou: 1.1756\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 6s - loss: 2.4888 - avg_iou: 1.2408 - val_loss: 1.9701 - val_avg_iou: 1.0557\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 6s - loss: 2.3053 - avg_iou: 0.6387 - val_loss: 1.8565 - val_avg_iou: 1.2905\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 6s - loss: 2.0460 - avg_iou: 1.1422 - val_loss: 1.4267 - val_avg_iou: 1.1120\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 6s - loss: 1.3803 - avg_iou: 1.0911 - val_loss: 1.4592 - val_avg_iou: 1.0281\n",
      "Epoch 18/30\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.6620 - avg_iou: 1.2396"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "import keras\n",
    "\n",
    "backup_path = '/home/ubuntu/dataset/backup/'\n",
    "# For Debugging purpose\n",
    "tf_board   = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0000001, patience=3, mode='min', verbose=1)\n",
    "save_model = keras.callbacks.LambdaCallback(on_epoch_end=lambda epoch,logs: model.save_weights(backup_path + 'yolov2-epoch%s-loss%s.weights'%(epoch, str(logs.get('loss')))))\n",
    "\n",
    "\n",
    "# Load pretrain weights\n",
    "# model.load_weights(\"yolov2.weights\")\n",
    "\n",
    "# Set up Data parallelism\n",
    "n_gpus = get_gpus()\n",
    "if n_gpus > 1:\n",
    "    BATCH_SIZE = n_gpus * BATCH_SIZE\n",
    "    model_par = make_parallel(model, n_gpus)\n",
    "else:\n",
    "    model_par = model\n",
    "\n",
    "# Set up optimizer\n",
    "\n",
    "\n",
    "adam = Adam(LEARN_RATE)\n",
    "# sgd = SGD(LEARN_RATE, decay=0.0005, momentum=0.9)\n",
    "def schedule(epochs):\n",
    "    if epochs < 20:\n",
    "        return LEARN_RATE\n",
    "    if 20 <= epochs <= 25:\n",
    "        return LEARN_RATE / 10.\n",
    "    if epochs >= 25:\n",
    "        return LEARN_RATE / 100.\n",
    "\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(schedule)\n",
    "   \n",
    "# Compiling model\n",
    "model_par.compile(optimizer=adam,loss=custom_loss, metrics=[avg_iou])\n",
    "\n",
    "hist =  model_par.fit_generator(generator     = train_data_gen, \n",
    "                            steps_per_epoch   = 5, \n",
    "                            validation_data   = val_data_gen,\n",
    "                            validation_steps  = 2,\n",
    "                            epochs            = 30, \n",
    "                            callbacks         = [tf_board, lr_scheduler],\n",
    "                            workers=1, verbose=1)\n",
    "\n",
    "model.save_weights('yolov2.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-GPUs Training - Data Parallelism Approach\n",
    "\n",
    "* Each GPU will have a copy of the model\n",
    "* During training time, mean of all gradidents from each GPU will be calculated to update the model\n",
    "<img style=\"width:40%\" src=\"https://www.tensorflow.org/images/Parallelism.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('yolov2.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training process using Tensorboard\n",
    "Open `http://<public-dns>:6006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# samples, labels = train_data_gen.next()\n",
    "# i = 2\n",
    "# img    = samples[i]\n",
    "# labels = labels.reshape([-1, 30, 40, 5, 36])\n",
    "# box    = labels[i][8][30][0][:4]*np.array([1280, 960, 1280, 960])\n",
    "# print(box)\n",
    "\n",
    "# dot    = cv2.circle(img, (int(box[0]), int(box[1])), radius=5, color=[0, 1, 0], thickness=5)\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.utils import shuffle\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# def extract_sign(img, bbox, output_size=(32, 32)):\n",
    "#     xc, yc, w, h = bbox.x, bbox.y, bbox.w, bbox.h\n",
    "#     x1   = int(xc - w/2)\n",
    "#     y1   = int(yc - h/2)\n",
    "#     x2   = int(xc + w/2)\n",
    "#     y2   = int(yc + h/2)\n",
    "#     roi = cv2.resize(img[y1:y2, x1:x2], output_size)\n",
    "#     return roi\n",
    "\n",
    "# x_train, y_train = shuffle(x_train, y_train)\n",
    "# fig = plt.figure(figsize=(17, 8))\n",
    "# for i, label in enumerate(labels):\n",
    "#     ax           = fig.add_subplot(4, 8, 1 + i, xticks=[], yticks=[])\n",
    "#     idx          = np.where(y_train[:, 1] == label)[0][0]\n",
    "#     img          = cv2.cvtColor(cv2.imread(x_train[idx]), cv2.COLOR_BGR2RGB)\n",
    "#     box          = y_train[idx][0]\n",
    "#     sign_only    = extract_sign(img, box, (32, 32)) #  just extract the sign\n",
    "#     ax.set_title(label)\n",
    "#     plt.imshow(sign_only)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
