{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning YOLOv2 on LISA Dataset\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "* What is Transfer learning\n",
    "* Relationship between COCO and LISA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.1 |Continuum Analytics, Inc.| (default, Mar 22 2017, 19:54:23) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version) # Check Python Version\n",
    "import os\n",
    "from keras.optimizers import Adam\n",
    "from cfg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LISA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ground truth boxes: 3672 boxes\n",
      "Train: 3672 samples\n",
      "Number of classes: 31\n",
      "\n",
      "Label Sample: \n",
      "[1093.5 408.0 45.0 48.0 'doNotEnter']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.parse_input import load_data    # Data handler for LISA dataset\n",
    "\n",
    "x_train, y_train = load_data('training.txt')\n",
    "labels           = np.unique(y_train[:,1])\n",
    "num_classes      = len(labels)            # Count number of classes in the dataset\n",
    "\n",
    "print(\"Train: {} samples\\nNumber of classes: {}\".format(len(x_train),num_classes))\n",
    "print(\"\\nLabel Sample: \\n{}\".format(y_train[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained YOLOv2 on COCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model.yolov2 import YOLOv2, darknet19\n",
    "import keras.backend as K\n",
    "K.clear_session() # Avoid duplicate model \n",
    "\n",
    "# Original YOLOv2 - Trained on COCO Dataset\n",
    "\n",
    "darknet19 = darknet19(freeze_layers=False)\n",
    "yolov2    = YOLOv2(feature_extractor=darknet19, num_anchors=5, num_classes=80)\n",
    "# print(yolov2.model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning - Cut last layer and create a new Conv2D for Traffic Sign Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "# Transfer Learning -RISSNet based on YOLOv2 by \n",
    "# Cut last layer\n",
    "topless_model = Model(yolov2.model.input, yolov2.model.layers[-2].output)\n",
    "\n",
    "# Create new Conv2D layer for Traffic Sign Detection\n",
    "traffic_sign_layer = Conv2D(filters=(N_ANCHORS* (N_CLASSES + 5)),\n",
    "                            kernel_size=(1, 1), kernel_regularizer=l2(5e-4), name='yolov2')(topless_model.output)\n",
    "\n",
    "# # Freeze topless layers\n",
    "# for layer in topless_model.layers[:-16]:\n",
    "#     layer.trainable = False\n",
    "    \n",
    "# Build a new Model for training\n",
    "model = Model(yolov2.model.input, traffic_sign_layer)\n",
    "model.load_weights('../yolo-coco.h5', by_name=True)\n",
    "\n",
    "# model.summary()\n",
    "# for l in model.layers:\n",
    "#     print(l.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    SCALE_NOOB, SCALE_CONF, SCALE_COOR, SCALE_PROB = 0.5, 5.0, 5.0, 1.0\n",
    "    pred_shape = K.shape(y_pred)[1:3]\n",
    "    gt_shape   = K.shape(y_true)                 # shape of ground truth value\n",
    "    GRID_H = tf.cast(pred_shape[0], tf.int32)  # shape of output feature map\n",
    "    GRID_W = tf.cast(pred_shape[1], tf.int32)\n",
    "    \n",
    "    output_size = tf.cast(tf.reshape([GRID_W, GRID_H], [1,1,1,1,2]), tf.float32)\n",
    "    y_pred = tf.reshape(y_pred,[-1, pred_shape[0], pred_shape[1], N_ANCHORS, N_CLASSES +5])\n",
    "    y_true = tf.reshape(y_true,[-1, gt_shape[1], gt_shape[2], N_ANCHORS, N_CLASSES + 5])\n",
    "\n",
    "    c_xy = _create_offset_map(K.shape(y_pred))\n",
    "    \n",
    "    pred_box_xy = (tf.sigmoid(y_pred[:,:,:,:,:2]) + c_xy)  / output_size\n",
    "    pred_box_wh = tf.exp(y_pred[:,:,:,:,2:4]) * np.reshape(ANCHORS, [1,1,1,N_ANCHORS,2])\n",
    "    pred_box_wh = tf.sqrt(pred_box_wh / output_size)\n",
    "    \n",
    "    # adjust confidence\n",
    "    pred_box_conf = tf.expand_dims(tf.sigmoid(y_pred[:, :, :, :, 4]), -1) \n",
    "    # adjust probability\n",
    "    pred_box_prob = tf.nn.softmax(y_pred[:, :, :, :, 5:])\n",
    "    \n",
    "    y_pred = tf.concat([pred_box_xy, pred_box_wh, pred_box_conf, pred_box_prob], 4)\n",
    "    \n",
    "    ### Adjust ground truth\n",
    "    center_xy = y_true[:,:,:,:,0:2]\n",
    "    true_box_xy = center_xy \n",
    "    true_box_wh = tf.sqrt(y_true[:,:,:,:,2:4])\n",
    "    \n",
    "    # adjust confidence\n",
    "    pred_tem_wh = tf.pow(pred_box_wh, 2) *  output_size\n",
    "    pred_box_area = pred_tem_wh[:,:,:,:,0] * pred_tem_wh[:,:,:,:,1]\n",
    "    pred_box_ul = pred_box_xy - 0.5 * pred_tem_wh\n",
    "    pred_box_bd = pred_box_xy + 0.5 * pred_tem_wh\n",
    "    \n",
    "    true_tem_wh = tf.pow(true_box_wh, 2) *  output_size\n",
    "    true_box_area = true_tem_wh[:,:,:,:,0] * true_tem_wh[:,:,:,:,1]\n",
    "    true_box_ul = true_box_xy - 0.5 * true_tem_wh\n",
    "    true_box_bd = true_box_xy + 0.5 * true_tem_wh\n",
    "    \n",
    "    intersect_ul = tf.maximum(pred_box_ul, true_box_ul) \n",
    "    intersect_br = tf.minimum(pred_box_bd, true_box_bd)\n",
    "    intersect_wh = intersect_br - intersect_ul\n",
    "    intersect_wh = tf.maximum(intersect_wh, 0.0)\n",
    "    intersect_area = intersect_wh[:,:,:,:,0] * intersect_wh[:,:,:,:,1]\n",
    "    \n",
    "    iou = tf.truediv(intersect_area, true_box_area + pred_box_area - intersect_area)\n",
    "    best_box = tf.equal(iou, tf.reduce_max(iou, [3], True)) \n",
    "    best_box = tf.to_float(best_box)\n",
    "    true_box_conf = tf.expand_dims(best_box * y_true[:,:,:,:,4], -1)\n",
    "    \n",
    "    # adjust confidence\n",
    "    true_box_prob = y_true[:,:,:,:,5:]\n",
    "    \n",
    "    y_true = tf.concat([true_box_xy, true_box_wh, true_box_conf, true_box_prob], 4)\n",
    "    \n",
    "    ### Compute the weights\n",
    "    weight_coor = tf.concat(4 * [true_box_conf], 4)\n",
    "    weight_coor = SCALE_COOR * weight_coor\n",
    "    weight_conf = SCALE_NOOB * (1. - true_box_conf) + SCALE_CONF * true_box_conf\n",
    "    weight_prob = tf.concat(N_CLASSES * [true_box_conf], 4) \n",
    "    weight_prob = SCALE_PROB * weight_prob \n",
    "    \n",
    "    weight = tf.concat([weight_coor, weight_conf, weight_prob], 4)\n",
    "    \n",
    "    ### Finalize the loss\n",
    "    loss = tf.pow(y_pred - y_true, 2)\n",
    "    loss = loss * weight\n",
    "    loss = tf.reshape(loss, [-1, tf.cast(GRID_W*GRID_H, tf.int32)*N_ANCHORS*(4 + 1 + N_CLASSES)])\n",
    "    loss = tf.reduce_sum(loss, 1)\n",
    "    loss = .5 * tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def _create_offset_map(output_shape):\n",
    "    \"\"\"\n",
    "    In Yolo9000 paper, grid map\n",
    "    \"\"\"\n",
    "    GRID_H = tf.cast(output_shape[1], tf.int32)  # shape of output feature map\n",
    "    GRID_W = tf.cast(output_shape[2], tf.int32)\n",
    "    \n",
    "    cx = tf.cast((K.arange(0, stop=GRID_W)), dtype=tf.float32)\n",
    "    cx = K.tile(cx, [GRID_H])\n",
    "    cx = K.reshape(cx, [-1, GRID_H, GRID_W, 1])\n",
    "\n",
    "    cy = K.cast((K.arange(0, stop=GRID_H)), dtype=tf.float32)\n",
    "    cy = K.reshape(cy, [-1, 1])\n",
    "    cy = K.tile(cy, [1, GRID_W])  \n",
    "    cy = K.reshape(cy, [-1])    \n",
    "    cy = K.reshape(cy, [-1, GRID_H, GRID_W, 1])\n",
    "\n",
    "    c_xy = tf.stack([cx, cy], -1)\n",
    "    c_xy = K.cast(c_xy, tf.float32)\n",
    "\n",
    "    return c_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.multi_gpu import make_parallel, get_gpus\n",
    "from utils.data_generator import flow_from_list\n",
    "\n",
    "# # HYPER-PARAMETERS\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS     = 20\n",
    "LEARN_RATE = 0.0001 # this model has been pre-trained, LOWER LR is needed\n",
    "\n",
    "# Data Generator\n",
    "train_data_gen = flow_from_list(x_train, y_train, batch_size=BATCH_SIZE, augment_data=True)\n",
    "\n",
    "backup_path = '/home/ubuntu/dataset/backup/'\n",
    "# For Debugging purpose\n",
    "tf_board   = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.000001, patience=3, mode='min', verbose=1)\n",
    "save_model = keras.callbacks.LambdaCallback(on_epoch_end=lambda epoch,logs: model.save_weights(backup_path + 'yolov2-epoch%s-loss%s.weights'%(epoch, str(logs.get('loss')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is(are) 1 GPU(s) on device.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[8,480,640,64]\n\t [[Node: batch_normalization_2/moments/sufficient_statistics/Sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_2/convolution, batch_normalization_2/moments/StopGradient)]]\n\t [[Node: batch_normalization_7/moments/sufficient_statistics/Gather/_1107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_3812_batch_normalization_7/moments/sufficient_statistics/Gather\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'batch_normalization_2/moments/sufficient_statistics/Sub', defined at:\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-ed8b994286cd>\", line 7, in <module>\n    darknet19 = darknet19(freeze_layers=False)\n  File \"/home/ubuntu/dataset/yolov2/model/darknet19.py\", line 28, in darknet19\n    x = conv_block(x, 64, (3, 3))\n  File \"/home/ubuntu/dataset/yolov2/model/net_builder.py\", line 19, in conv_block\n    x = BatchNormalization()(x)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/keras/engine/topology.py\", line 578, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/keras/layers/normalization.py\", line 140, in call\n    epsilon=self.epsilon)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1482, in normalize_batch_in_training\n    shift=None, name=None, keep_dims=False)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 617, in moments\n    y, axes, shift=shift, keep_dims=keep_dims, name=name)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 534, in sufficient_statistics\n    m_ss = math_ops.subtract(x, shift)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 282, in subtract\n    return gen_math_ops._sub(x, y, name)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2775, in _sub\n    result = _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[8,480,640,64]\n\t [[Node: batch_normalization_2/moments/sufficient_statistics/Sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_2/convolution, batch_normalization_2/moments/StopGradient)]]\n\t [[Node: batch_normalization_7/moments/sufficient_statistics/Gather/_1107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_3812_batch_normalization_7/moments/sufficient_statistics/Gather\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,480,640,64]\n\t [[Node: batch_normalization_2/moments/sufficient_statistics/Sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_2/convolution, batch_normalization_2/moments/StopGradient)]]\n\t [[Node: batch_normalization_7/moments/sufficient_statistics/Gather/_1107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_3812_batch_normalization_7/moments/sufficient_statistics/Gather\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e4349aa0fe15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                             \u001b[0mepochs\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                             \u001b[0mcallbacks\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                             workers=1, verbose=1, max_q_size=3)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov2.weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1875\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1876\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,480,640,64]\n\t [[Node: batch_normalization_2/moments/sufficient_statistics/Sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_2/convolution, batch_normalization_2/moments/StopGradient)]]\n\t [[Node: batch_normalization_7/moments/sufficient_statistics/Gather/_1107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_3812_batch_normalization_7/moments/sufficient_statistics/Gather\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'batch_normalization_2/moments/sufficient_statistics/Sub', defined at:\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-ed8b994286cd>\", line 7, in <module>\n    darknet19 = darknet19(freeze_layers=False)\n  File \"/home/ubuntu/dataset/yolov2/model/darknet19.py\", line 28, in darknet19\n    x = conv_block(x, 64, (3, 3))\n  File \"/home/ubuntu/dataset/yolov2/model/net_builder.py\", line 19, in conv_block\n    x = BatchNormalization()(x)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/keras/engine/topology.py\", line 578, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/keras/layers/normalization.py\", line 140, in call\n    epsilon=self.epsilon)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1482, in normalize_batch_in_training\n    shift=None, name=None, keep_dims=False)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 617, in moments\n    y, axes, shift=shift, keep_dims=keep_dims, name=name)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 534, in sufficient_statistics\n    m_ss = math_ops.subtract(x, shift)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 282, in subtract\n    return gen_math_ops._sub(x, y, name)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2775, in _sub\n    result = _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/anaconda2/envs/yad2k/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[8,480,640,64]\n\t [[Node: batch_normalization_2/moments/sufficient_statistics/Sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_2/convolution, batch_normalization_2/moments/StopGradient)]]\n\t [[Node: batch_normalization_7/moments/sufficient_statistics/Gather/_1107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_3812_batch_normalization_7/moments/sufficient_statistics/Gather\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "# Load pretrain weights\n",
    "model.load_weights(\"yolov2.weights\")\n",
    "\n",
    "# Set up Data parallelism\n",
    "n_gpus = get_gpus()\n",
    "if n_gpus > 1:\n",
    "    BATCH_SIZE = n_gpus * BATCH_SIZE\n",
    "    model_par = make_parallel(model, n_gpus)\n",
    "else:\n",
    "    model_par = model\n",
    "\n",
    "# Set up optimizer\n",
    "# sgd = SGD(LEARN_RATE, decay=0.0005, momentum=0.9)\n",
    "adam = Adam(LEARN_RATE)\n",
    "# Compiling model\n",
    "model_par.compile(optimizer=adam,loss=custom_loss)\n",
    "\n",
    "hist =  model_par.fit_generator(generator     = train_data_gen, \n",
    "                            steps_per_epoch   = 200, \n",
    "                            epochs            = 2, \n",
    "                            callbacks         = [tf_board, early_stop, save_model],\n",
    "                            workers=1, verbose=1, max_q_size=3)\n",
    "\n",
    "model.save_weights('yolov2.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-GPUs Training - Data Parallelism Approach\n",
    "\n",
    "* Each GPU will have a copy of the model\n",
    "* During training time, mean of all gradidents from each GPU will be calculated to update the model\n",
    "<img style=\"width:40%\" src=\"https://www.tensorflow.org/images/Parallelism.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('yolov2.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training process using Tensorboard\n",
    "Open `http://<public-dns>:6006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# samples, labels = train_data_gen.next()\n",
    "# i = 2\n",
    "# img    = samples[i]\n",
    "# labels = labels.reshape([-1, 30, 40, 5, 36])\n",
    "# box    = labels[i][8][30][0][:4]*np.array([1280, 960, 1280, 960])\n",
    "# print(box)\n",
    "\n",
    "# dot    = cv2.circle(img, (int(box[0]), int(box[1])), radius=5, color=[0, 1, 0], thickness=5)\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.utils import shuffle\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# def extract_sign(img, bbox, output_size=(32, 32)):\n",
    "#     xc, yc, w, h = bbox.x, bbox.y, bbox.w, bbox.h\n",
    "#     x1   = int(xc - w/2)\n",
    "#     y1   = int(yc - h/2)\n",
    "#     x2   = int(xc + w/2)\n",
    "#     y2   = int(yc + h/2)\n",
    "#     roi = cv2.resize(img[y1:y2, x1:x2], output_size)\n",
    "#     return roi\n",
    "\n",
    "# x_train, y_train = shuffle(x_train, y_train)\n",
    "# fig = plt.figure(figsize=(17, 8))\n",
    "# for i, label in enumerate(labels):\n",
    "#     ax           = fig.add_subplot(4, 8, 1 + i, xticks=[], yticks=[])\n",
    "#     idx          = np.where(y_train[:, 1] == label)[0][0]\n",
    "#     img          = cv2.cvtColor(cv2.imread(x_train[idx]), cv2.COLOR_BGR2RGB)\n",
    "#     box          = y_train[idx][0]\n",
    "#     sign_only    = extract_sign(img, box, (32, 32)) #  just extract the sign\n",
    "#     ax.set_title(label)\n",
    "#     plt.imshow(sign_only)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3",
   "language": "python",
   "name": "yad2k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
