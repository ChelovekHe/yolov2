{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train YOLOv2 on LISA Dataset\n",
    "-----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.13 |Anaconda 4.4.0 (64-bit)| (default, Dec 20 2016, 23:09:15) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version) # Check Python Version\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.optimizers import Adam\n",
    "from utils.parse_input import load_data    # Data handler for LISA dataset\n",
    "from cfg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare LISA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ground truth boxes: 3672 boxes\n",
      "Train: 3672 samples\n",
      "Number of classes: 31\n",
      "\n",
      "Label Sample: \n",
      "[1093.5 408.0 45.0 48.0 'doNotEnter']\n",
      "\n",
      "\n",
      "Relative Anchors using K-mean clustering [K=5]\n",
      " [[ 0.0237179   0.03571576]\n",
      " [ 0.05957714  0.08738709]\n",
      " [ 0.08816277  0.1294925 ]\n",
      " [ 0.03283318  0.04838902]\n",
      " [ 0.04450034  0.06430861]]\n"
     ]
    }
   ],
   "source": [
    "pretrained_path = \"/home/ubuntu/dataset/darknet19_544.weights\"\n",
    "\n",
    "x_train, y_train = load_data('data/training.txt')\n",
    "labels           = np.unique(y_train[:,1])\n",
    "num_classes      = len(labels)            # Count number of classes in the dataset\n",
    "print(\"Train: {} samples\\nNumber of classes: {}\".format(len(x_train),num_classes))\n",
    "print(\"\\nLabel Sample: \\n{}\".format(y_train[0]))\n",
    "print(\"\\n\\nRelative Anchors using K-mean clustering [K=5]\\n {}\".format(ANCHORS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct YOLOv2 On Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained weights have been loaded into model\n"
     ]
    }
   ],
   "source": [
    "from model.yolov2 import YOLOv2, darknet19\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session() # Avoid duplicate model\n",
    "\n",
    "darknet19 = darknet19(pretrained_path, freeze_layers=True)\n",
    "yolov2    = YOLOv2(feature_extractor=darknet19, num_anchors=len(ANCHORS), num_classes=N_CLASSES)\n",
    "model     = yolov2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# @TODO:\n",
    "#    - processed boxes are ALL relative, no sqrt \n",
    "#    - tf.sqrt to make value bigger \n",
    "#    - Data gnerator label [ batch, 36]\n",
    "\n",
    "def _process_gt(y_true, output_shape):\n",
    "    \"\"\"\n",
    "    Process ground truth output\n",
    "    \"\"\"\n",
    "    OUTPUT_W = tf.cast(output_shape[0], tf.int32)\n",
    "    OUTPUT_H = tf.cast(output_shape[1], tf.int32)\n",
    "    \n",
    "    y_true   = K.reshape(y_true, [-1, OUTPUT_W, OUTPUT_H, N_ANCHORS, N_CLASSES + 5])\n",
    "    true_boxes = y_true[...,:4]\n",
    "    true_conf  = y_true[..., 4]\n",
    "    true_clf   = y_true[...,5:]\n",
    "    \n",
    "    return true_boxes, true_conf, true_clf\n",
    "\n",
    "\n",
    "def _process_prediction(y_pred):\n",
    "    \n",
    "    output_shape   = K.shape(y_pred)[1:3]\n",
    "    OUTPUT_W = tf.cast(output_shape[0], tf.int32)\n",
    "    OUTPUT_H = tf.cast(output_shape[1], tf.int32)\n",
    "    \n",
    "    # Scaled anchors to size of feature map\n",
    "    scaled_anchors = ANCHORS*K.cast(K.reshape([OUTPUT_W, OUTPUT_H], [1, 1, 1, 1, 2]), tf.float32)\n",
    "    anchor_tensor  = K.reshape(scaled_anchors, [1, 1, 1, N_ANCHORS, 2])\n",
    "    y_pred         = K.reshape(y_pred, [-1, output_shape[0], output_shape[1], N_ANCHORS, N_CLASSES + 5])\n",
    "    \n",
    "    # Create offset map\n",
    "    cx, cy = _create_offset_map(K.shape(y_pred))\n",
    "    px     = tf.cast(anchor_tensor[...,0], dtype=tf.float32)\n",
    "    py     = tf.cast(anchor_tensor[..., 1], dtype=tf.float32)\n",
    "    \n",
    "    # Calculate Prediction in relative position (percentage)\n",
    "    OUTPUT_SIZE = tf.cast(output_shape, tf.float32)\n",
    "    bx  = (tf.sigmoid(y_pred[..., 0]) + cx) / OUTPUT_SIZE[0]\n",
    "    by  = (tf.sigmoid(y_pred[..., 1]) + cy) / OUTPUT_SIZE[1]\n",
    "    bw  = px * tf.exp(y_pred[..., 2])       / OUTPUT_SIZE[0]\n",
    "    bh  = py * tf.exp(y_pred[..., 3])       / OUTPUT_SIZE[1]\n",
    "    \n",
    "    pred_boxes = tf.stack([bx, by, bw, bh], -1)\n",
    "    pred_conf  = tf.sigmoid(y_pred[..., 4]) # to = sig\n",
    "    pred_clf   = tf.nn.softmax(y_pred[..., 5:])\n",
    "\n",
    "    return pred_boxes, pred_conf, pred_clf\n",
    "    \n",
    "                           \n",
    "def _calc_iou(true_boxes, pred_boxes):\n",
    "    # Scaled anchors to size of feature map\n",
    "    output_shape   = K.shape(pred_boxes)[1:3]\n",
    "    \n",
    "    # Scale to input image\n",
    "    OUTPUT_SIZE =  K.cast(K.reshape([ SHRINK_FACTOR * output_shape[0], SHRINK_FACTOR * output_shape[1]], [1, 1, 1, 1, 2]), tf.float32)\n",
    "    \n",
    "    pred_xy     = pred_boxes[...,:2]    * OUTPUT_SIZE \n",
    "    pred_wh     = pred_boxes[..., 2:4]  * OUTPUT_SIZE \n",
    "    pred_area   = pred_wh[..., 0]       * pred_wh[..., 1]\n",
    "\n",
    "    true_xy     = true_boxes[...,:2]  * OUTPUT_SIZE \n",
    "    true_wh     = true_boxes[...,2:4] * OUTPUT_SIZE \n",
    "    true_area   = true_wh[..., 0]     * true_wh[..., 1]\n",
    "    \n",
    "    # Calculate IoU between ground truth and prediction\n",
    "    intersect_ul   = tf.maximum(pred_xy - 0.5 *  pred_wh, true_xy - 0.5 * true_wh)\n",
    "    intersect_br   = tf.minimum(pred_xy + 0.5 *  pred_wh, true_xy + 0.5 * true_wh)\n",
    "    intersect_wh   = tf.maximum(intersect_br - intersect_ul, 0.0)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    iou = tf.truediv(intersect_area, true_area + pred_area - intersect_area)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "    \n",
    "def _create_offset_map(output_shape):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    GRID_W    = tf.cast(output_shape[1], tf.int32)\n",
    "    GRID_H    = tf.cast(output_shape[2], tf.int32)\n",
    "    N_ANCHORS = len(ANCHORS)\n",
    "\n",
    "    cx = tf.cast((K.arange(0, stop=GRID_H)), dtype=tf.float32)\n",
    "    cx = K.expand_dims(cx, -1)\n",
    "    cx = K.tile(cx, (GRID_W, N_ANCHORS))\n",
    "    cx = K.reshape(cx, [-1, GRID_W, GRID_H, N_ANCHORS])\n",
    "\n",
    "    cy = K.cast((K.arange(0, stop=GRID_W)), dtype=tf.float32)\n",
    "    cy = K.reshape(cy, [-1, 1])\n",
    "    cy = K.tile(cy, [1, N_ANCHORS*GRID_H])  \n",
    "    cy = K.reshape(cy, [-1])    \n",
    "    cy = K.reshape(cy, [-1, GRID_W, GRID_H, N_ANCHORS])\n",
    "    \n",
    "    return cx, cy\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true: shape [BATCH, NUM_CLASSES + 5]\n",
    "    y_pred: [BATCH, OUTPUT_W, OUTPUT_H, N_ANCHORS, N_CLASSES + 5]\n",
    "    \n",
    "    y_true provides: [xc, yc, w, h, conf, class_prob]\n",
    "    y\n",
    "    \"\"\"\n",
    "    pred_shape = K.shape(y_pred)[1:3]\n",
    "\n",
    "    true_boxes, true_conf, true_cls = _process_gt(y_true, pred_shape)\n",
    "    pred_boxes, pred_conf, pred_cls = _process_prediction(y_pred)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou           = _calc_iou(true_boxes, pred_boxes)\n",
    "    tf.summary.scalar('avg_iou', tf.reduce_mean(iou))\n",
    "    \n",
    "    # Create detection mask\n",
    "    best_box      = tf.equal(iou, tf.reduce_max(iou, [3], True)) \n",
    "    best_box      = tf.to_float(best_box)\n",
    "    true_conf     = tf.expand_dims(best_box * true_conf, -1)   # sigmoid(to) = P(object) * IoU\n",
    "    pred_conf     = tf.expand_dims(pred_conf, -1)\n",
    "    \n",
    "    # Coordinate Loss   @TODO: sqrt of wh\n",
    "    weight_coor = 5.0 * tf.concat(2 * [true_conf], 4)\n",
    "    sqrt_true_wh = tf.sqrt(true_boxes[..., 2:4])\n",
    "    sqrt_pred_wh = tf.sqrt(pred_boxes[..., 2:4])\n",
    "\n",
    "    xy_loss   = tf.pow(true_boxes[..., :2] - pred_boxes[...,:2], 2) * weight_coor\n",
    "    wh_loss   = tf.pow(sqrt_true_wh - sqrt_pred_wh, 2) * weight_coor\n",
    "    coor_loss = tf.concat([xy_loss, wh_loss], 4)\n",
    "    \n",
    "    # Objectiveness - Loss\n",
    "    weight_conf = 0.5 * (1. - true_conf) + 5.0 * true_conf\n",
    "    obj_loss    = tf.pow(true_conf - pred_conf, 2) * weight_conf\n",
    "    \n",
    "    # Classifier Loss\n",
    "    weight_prob = 1.0 * tf.concat(N_CLASSES * [true_conf], 4) \n",
    "    clf_loss    = tf.pow(true_cls - pred_cls, 2) * weight_prob\n",
    "    \n",
    "    # Total loss\n",
    "    loss = tf.concat([coor_loss, obj_loss, clf_loss], 4)\n",
    "    loss = tf.reshape(loss, [-1, 30*40*N_ANCHORS*(4 + 1 + N_CLASSES)])\n",
    "    loss = tf.reduce_sum(loss, 1)\n",
    "    loss = .5 * tf.reduce_mean(loss)\n",
    "    \n",
    "    # Write summary\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is(are) 1 GPU(s) on device.\n",
      "Epoch 1/10\n",
      " 16/459 [>.............................] - ETA: 1018s - loss: 452.5739"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import keras\n",
    "from utils.data_generator import flow_from_list\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.multi_gpu import make_parallel, get_gpus\n",
    "\n",
    "# HYPER-PARAMETERS\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS     = 10\n",
    "LEARN_RATE = 1e-6\n",
    "\n",
    "\n",
    "# Data Generator\n",
    "train_data_gen = flow_from_list(x_train, y_train, batch_size=BATCH_SIZE, augment_data=True)\n",
    "\n",
    "# For Debugging purpose\n",
    "tf_board   = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=3, mode='min', verbose=1)\n",
    "save_moldel= keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch,logs: model.save_weights('/home/ubuntu/dataset/backup/yolov2-epoch%s-loss:%s.weights'%(epoch, str(logs.get('loss')))))\n",
    "\n",
    "# TRAIN ON MULTI-GPUS\n",
    "n_gpus = get_gpus()\n",
    "if n_gpus > 1:\n",
    "    BATCH_SIZE = n_gpus * BATCH_SIZE\n",
    "    model_par = make_parallel(model, n_gpus)\n",
    "else:\n",
    "    model_par = model\n",
    "\n",
    "model_par.compile(optimizer=Adam(LEARN_RATE),loss=custom_loss)\n",
    "hist =  model_par.fit_generator(generator   = train_data_gen, \n",
    "                            steps_per_epoch = len(x_train)/BATCH_SIZE, \n",
    "                            epochs          = 10, \n",
    "                            callbacks       = [tf_board, early_stop, save_moldel],\n",
    "                            workers=1, verbose=1)\n",
    "\n",
    "model.save_weights('yolov2.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-GPUs Training - Data Parallelism Approach\n",
    "\n",
    "* Each GPU will have a copy of the model\n",
    "* During training time, mean of all gradidents from each GPU will be calculated to update the model\n",
    "<img style=\"width:40%\" src=\"https://www.tensorflow.org/images/Parallelism.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training process using Tensorboard\n",
    "Open `http://<public-dns>:6006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def extract_sign(img, bbox, output_size=(32, 32)):\n",
    "    xc, yc, w, h = bbox.x, bbox.y, bbox.w, bbox.h\n",
    "    x1   = int(xc - w/2)\n",
    "    y1   = int(yc - h/2)\n",
    "    x2   = int(xc + w/2)\n",
    "    y2   = int(yc + h/2)\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    roi = cv2.resize(roi, output_size)\n",
    "    return roi\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "fig = plt.figure(figsize=(17, 8))\n",
    "for i, label in enumerate(labels):\n",
    "    ax           = fig.add_subplot(4, 8, 1 + i, xticks=[], yticks=[])\n",
    "    idx          = np.where(y_train[:, 1] == label)[0][0]\n",
    "    img          = cv2.cvtColor(cv2.imread(x_train[idx]), cv2.COLOR_BGR2RGB)\n",
    "    box          = y_train[idx][0]\n",
    "    sign_only    = extract_sign(img, box, (32, 32)) #  just extract the sign\n",
    "    ax.set_title(label)\n",
    "    plt.imshow(sign_only)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1.  + np.exp(-x))\n",
    "\n",
    "def interpret_netout(image, netout):\n",
    "    output_shape = K.shape(netout)\n",
    "    boxes = []\n",
    "    with sess.as_default():\n",
    "        GRID_W = tf.cast(output_shape[0], tf.int32).eval()\n",
    "        GRID_H = tf.cast(output_shape[1], tf.int32).eval()\n",
    "    \n",
    "    netout = np.reshape(netout, [GRID_W, GRID_H, len(ANCHORS), -1])\n",
    "    # interpret the output by the network\n",
    "    print(GRID_W, GRID_H)\n",
    "    print(np.shape(netout))\n",
    "    for row in range(GRID_W):\n",
    "        for col in range(GRID_H):\n",
    "            for b in range(len(ANCHORS)):\n",
    "                box = BoundBox(N_CLASSES)\n",
    "\n",
    "                # first 5 weights for x, y, w, h and confidence\n",
    "                box.x, box.y, box.w, box.h, box.c = netout[row, col, b,:5]\n",
    "                box.x = (col + sigmoid(box.x)) / GRID_W\n",
    "                box.y = (row + sigmoid(box.y)) / GRID_H\n",
    "#                 box.w = ANCHORS[b][0] * np.exp(box.w) / GRID_W\n",
    "#                 box.h = ANCHORS[b][1] * np.exp(box.h) / GRID_H\n",
    "                box.w = ANCHORS[b][0] * np.exp(box.w)\n",
    "                box.h = ANCHORS[b][1] * np.exp(box.h)\n",
    "                box.c = sigmoid(box.c)\n",
    "\n",
    "                # last  weights for class probabilities\n",
    "                classes = netout[row,col,b,5:]\n",
    "                box.probs = softmax(classes) * box.c # P(obj|class) = P(obj)*softmax(P(classes))\n",
    "                box.probs *= box.probs > THRESHOLD\n",
    "                boxes.append(box)\n",
    "\n",
    "    # suppress non-maximal boxes\n",
    "    for c in range(N_CLASSES):\n",
    "        sorted_indices = list(reversed(np.argsort([box.probs[c] for box in boxes])))\n",
    "\n",
    "        for i in xrange(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            \n",
    "            if boxes[index_i].probs[c] == 0: \n",
    "                continue\n",
    "            else:\n",
    "                for j in xrange(i+1, len(sorted_indices)):\n",
    "                    index_j = sorted_indices[j]\n",
    "                    \n",
    "                    if boxes[index_i].iou(boxes[index_j]) >= 0.4:\n",
    "                        boxes[index_j].probs[c] = 0\n",
    "\n",
    "    # draw the boxes using a threshold\n",
    "    for box in boxes:\n",
    "        max_indx = np.argmax(box.probs)\n",
    "        max_prob = box.probs[max_indx]\n",
    "        if max_prob > THRESHOLD:\n",
    "            xmin  = int((box.x - box.w/2) * image.shape[1])\n",
    "            xmax  = int((box.x + box.w/2) * image.shape[1])\n",
    "            ymin  = int((box.y - box.h/2) * image.shape[0])\n",
    "            ymax  = int((box.y + box.h/2) * image.shape[0])\n",
    "            print((xmin,ymin), (xmax,ymax))\n",
    "            print(max_indx)\n",
    "            cv2.rectangle(image, (xmin,ymin), (xmax,ymax),np.random.randint(0, 255, [3]), 3)\n",
    "            cv2.putText(image, LABELS[max_indx], (xmin, ymin - 12), 0, 1e-3 * image.shape[0], (0,255,0), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
