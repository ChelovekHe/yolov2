{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Anchors using K-mean clustering\n",
    "\n",
    "<img src=\"test_images/anchor_visualization.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "Anchor is a pre-defined width/height for the network to make network predict easier. Instead of directly predicting the network, our network predicts coordinate values `tx, ty, tw, th` for each cell in its output feature map. By indirectly predicting the position of bounding box relative to cell coordinates and using anchors, the network improve its numerical stabability and converge faster. \n",
    "\n",
    "In order to convert to bounding box, we use location of the cell `(cx, cy)`, where the center of the ground truth locates inside, and anchor `(pw, ph)` to scale the prediction as the following formula (note that everything is in relative size):\n",
    "````\n",
    "Transform Prediction into bounding box:\n",
    "bx = sigmoid(tx) + cx\n",
    "by = sigmoid(ty) + cy\n",
    "bw = pw * exp(tw)\n",
    "bh = ph * exp(th)\n",
    "````\n",
    "\n",
    "**K-mean Clustering**: Instead of hand-picking the anchors, we take advantage of training data to generate anchors based on the ground truth bounding boxes. This allows the network to converge faster. In this work, we selected 5 number of anchors as it is a good trade off between speed and accuracy. Having more anchors allows us to predict more accurately, however, it would also slow down the prediction speed. By plotting the `W` and `H` ratio, we might see that the width and height ratio is linearly dependent to its size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "label_path   = 'data/training.txt'  # lisa extension training data using save_lisa_to_txt(path_to_lisa_training)\n",
    "data = pd.read_csv(label_path, sep=\",\", header = None, names=['image','x1','y1','x2','y2','label'])\n",
    "data['w'] = data['x2'] - data['x1']\n",
    "data['h'] = data['y2'] - data['y1']\n",
    "data[0:2]\n",
    "# Visualize ratio between 'w' and 'y'\n",
    "data.plot.scatter(x='w',y='h', figsize=(10,10), s=1, title='Width/Height Ratio of Bounding Boxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scripts.generate_anchors import *\n",
    "\n",
    "k            = 5  # num_anchors\n",
    "loss_conv    = 1e-5\n",
    "img_size     = [1280, 960, 0]\n",
    "feature_map  = [d/32 for d in img_size]    # DarkNet19 on YOLOv2 Max-pool 5 times --> output'size shrinked 2^5 = 32 times\n",
    "gt_boxes = []\n",
    "\n",
    "with open(label_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        img_path, x1, y1, x2, y2, label = line.rstrip().split(\",\")\n",
    "        xc, yc, w, h = convert_bbox(x1, y1, x2, y2)\n",
    "        xc, yc, w, h = scale_rel_box(img_size, Box(xc, yc, w, h))\n",
    "        gt_boxes.append(Box(0, 0, float(w), float(h))) # since we calculate w h of anchors, we do not take xc yc into account\n",
    "print(\"Number of ground truth boxes: {} boxes\".format(len(gt_boxes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-MEAN CLUSTERING\n",
    "anchor_list = []\n",
    "avg_iou_list = []\n",
    "for k in list(range(1, 12)):\n",
    "    anchors, avg_iou = k_mean_cluster(k, gt_boxes, loss_convergence=1e-6)\n",
    "    print(\"K = {:2} | AVG_IOU:{:-4f} \".format(k, avg_iou))\n",
    "    anchor_list.append(anchors)\n",
    "    avg_iou_list.append(avg_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "marker_style = dict(color='cornflowerblue', linestyle=':', marker='o',\n",
    "                    markersize=15, markerfacecoloralt='gray')\n",
    "\n",
    "x = list(range(1, 12))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, avg_iou_list, fillstyle='full', **marker_style)\n",
    "plt.grid()\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "plt.xticks(np.arange(1, 12, 1.0))\n",
    "plt.xlim([1, 12] ) # this line\n",
    "plt.title(\"Effect of Number of Anchors on Average IoU\", fontsize=20)\n",
    "# print result\n",
    "print(\"Anchor [K =5] on LISA Dataset:\\n\")\n",
    "for anchor in anchor_list[4]:  # Select K = 5 \n",
    "    print(anchor.w , anchor.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "sample_data ='test_images/stop_1405106680.avi_image9.png'\n",
    "\n",
    "anchors = np.array(((0.023717899133663362, 0.035715759075907606),\n",
    "(0.03283318210930825, 0.0483890193566751),\n",
    "(0.04450034340659346, 0.064308608058608),\n",
    "(0.08816276658767774, 0.1294924960505529),\n",
    "(0.059577141608391594, 0.08738709207459215)))\n",
    "\n",
    "img = cv2.cvtColor(cv2.imread(sample_data), cv2.COLOR_BGR2RGB)\n",
    "height, width, c = img.shape\n",
    "\n",
    "shrink_factor = 32\n",
    "grid_w = list(range(width/shrink_factor))\n",
    "grid_h = list(range(height/shrink_factor))\n",
    "center = 0\n",
    "# Plot grid map\n",
    "for r in grid_w:\n",
    "    img = cv2.line(img,(r*shrink_factor, 0), (r*shrink_factor, height), color=(0, 255, 0), thickness=2)\n",
    "    \n",
    "for h in grid_h:\n",
    "    img = cv2.line(img,(0, h*shrink_factor), (width, h*shrink_factor), color=(0, 255, 0), thickness=2)\n",
    "    \n",
    "# Plot center point\n",
    "for r in grid_w:\n",
    "    for h in grid_h:\n",
    "        centroid = ((r + 1)*shrink_factor - shrink_factor/2, (h+1)*shrink_factor - shrink_factor/2)\n",
    "        img = cv2.circle(img, centroid, radius=1, color=(0, 255, 0), thickness=2)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(img)\n",
    "plt.title('Cell Map', fontsize=20)\n",
    "\n",
    "print(\"Anchors Absolute size:\")\n",
    "print(anchors*np.array([width, height]))\n",
    "center = (1090, 420)  # of stop sign - hand picked\n",
    "sample = cv2.circle(img, center, radius=2, color=(255, 255, 255), thickness=4)\n",
    "\n",
    "for i in range(len(anchors)):\n",
    "    p1 = center + anchors[i]*np.array([width, height])\n",
    "    p2 = center - anchors[i]*np.array([width, height])\n",
    "    result = cv2.rectangle(sample,tuple(p1.astype(int)),tuple(p2.astype(int)),(255, 255, int(255/(i+1))), thickness=2)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(result)\n",
    "plt.title(\"Anchors Visualization \", fontsize=20)\n",
    "result = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
